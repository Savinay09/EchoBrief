{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "\n",
    "from langchain import OpenAI\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n",
      "<torch.cuda.device object at 0x7f9b35453050>\n",
      "NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n"
     ]
    }
   ],
   "source": [
    "# Load the vtt_data.csv file\n",
    "# filter only use 'large' files\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "podcast_data = []\n",
    "row_num = 0\n",
    "with open('vtt_data.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='|')\n",
    "    for row in reader:\n",
    "        row_num += 1\n",
    "        \n",
    "        if row_num == 1:\n",
    "            continue\n",
    "            \n",
    "        filename = row[5]\n",
    "        if not filename.endswith(\"_large.vtt\"):\n",
    "            continue\n",
    "\n",
    "        podcast = {    \n",
    "            \"episode_index\": row[0],    \n",
    "            \"guest\": row[1],\n",
    "            \"episode_name\": row[2],\n",
    "            \"host_name\": row[3],\n",
    "            \"episode_number\": row[4],\n",
    "            \"transcript\": row[6],\n",
    "            \"duration\": row[7],\n",
    "        }\n",
    "        podcast_data.append(podcast)\n",
    "#         break\n",
    "\n",
    "print(len(podcast_data))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_title_summary_results(results):\n",
    "  out = []\n",
    "  for e in results:\n",
    "    e = e.replace('\\n', '')\n",
    "    if '|' in e:\n",
    "      processed = {'title': e.split('|')[0],\n",
    "                    'summary': e.split('|')[1][1:]\n",
    "                    }\n",
    "    elif ':' in e:\n",
    "      processed = {'title': e.split(':')[0],\n",
    "                    'summary': e.split(':')[1][1:]\n",
    "                    }\n",
    "    elif '-' in e:\n",
    "      processed = {'title': e.split('-')[0],\n",
    "                    'summary': e.split('-')[1][1:]\n",
    "                    }\n",
    "    else:\n",
    "      processed = {'title': '',\n",
    "                    'summary': e\n",
    "                    }\n",
    "    out.append(processed)\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_stage_1(chunks_text):\n",
    "  \n",
    "  print(f'Start time: {datetime.now()}')\n",
    "\n",
    "  # Prompt to get title and summary for each chunk\n",
    "  map_prompt_template = \"\"\"Firstly, give the following text an informative title. Then, on a new line, write a 75-100 word summary of the following text:\n",
    "  {text}\n",
    "\n",
    "  Return your answer in the following format:\n",
    "  Title | Summary...\n",
    "  e.g. \n",
    "  Why Artificial Intelligence is Good | AI can make humans more productive by automating many repetitive processes.\n",
    "\n",
    "  TITLE AND CONCISE SUMMARY:\"\"\"\n",
    "\n",
    "  map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "  # Define the LLMs\n",
    "  map_llm = ChatOllama(model=\"openchat\")\n",
    "    \n",
    "  map_llm_chain = LLMChain(llm = map_llm, prompt = map_prompt)\n",
    "  map_llm_chain_input = [{'text': t} for t in chunks_text]\n",
    "  # Run the input through the LLM chain (works in parallel)\n",
    "  map_llm_chain_results = map_llm_chain.apply(map_llm_chain_input)\n",
    "\n",
    "  stage_1_outputs = parse_title_summary_results([e['text'] for e in map_llm_chain_results])\n",
    "\n",
    "  print(f'Stage 1 done time {datetime.now()}')\n",
    "\n",
    "  return {\n",
    "    'stage_1_outputs': stage_1_outputs\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text_array):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "    # Use OpenAI to embed the summaries and titles. Size of _embeds: (num_chunks x 1536)\n",
    "    openai_embed = OpenAIEmbeddings()\n",
    "\n",
    "    return np.array(openai_embed.embed_documents(text_array))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the community detection algorithm\n",
    "\n",
    "def get_topics(title_similarity, num_topics = 8, bonus_constant = 0.25, min_size = 3):\n",
    "\n",
    "  proximity_bonus_arr = np.zeros_like(title_similarity)\n",
    "  for row in range(proximity_bonus_arr.shape[0]):\n",
    "    for col in range(proximity_bonus_arr.shape[1]):\n",
    "      if row == col:\n",
    "        proximity_bonus_arr[row, col] = 0\n",
    "      else:\n",
    "        proximity_bonus_arr[row, col] = 1/(abs(row-col)) * bonus_constant\n",
    "        \n",
    "  title_similarity += proximity_bonus_arr\n",
    "\n",
    "  title_nx_graph = nx.from_numpy_array(title_similarity)\n",
    "\n",
    "  desired_num_topics = num_topics\n",
    "  # Store the accepted partitionings\n",
    "  topics_title_accepted = []\n",
    "\n",
    "  resolution = 0.85\n",
    "  resolution_step = 0.01\n",
    "  iterations = 40\n",
    "\n",
    "  # Find the resolution that gives the desired number of topics\n",
    "  topics_title = []\n",
    "  while len(topics_title) not in [desired_num_topics, desired_num_topics + 1, desired_num_topics + 2]:\n",
    "    topics_title = community.louvain_communities(title_nx_graph, weight = 'weight', resolution = resolution)\n",
    "    resolution += resolution_step\n",
    "  topic_sizes = [len(c) for c in topics_title]\n",
    "  sizes_sd = np.std(topic_sizes)\n",
    "  modularity = community.modularity(title_nx_graph, topics_title, weight = 'weight', resolution = resolution)\n",
    "\n",
    "  lowest_sd_iteration = 0\n",
    "  # Set lowest sd to inf\n",
    "  lowest_sd = float('inf')\n",
    "\n",
    "  for i in range(iterations):\n",
    "    topics_title = community.louvain_communities(title_nx_graph, weight = 'weight', resolution = resolution)\n",
    "    modularity = community.modularity(title_nx_graph, topics_title, weight = 'weight', resolution = resolution)\n",
    "    \n",
    "    # Check SD\n",
    "    topic_sizes = [len(c) for c in topics_title]\n",
    "    sizes_sd = np.std(topic_sizes)\n",
    "    \n",
    "    topics_title_accepted.append(topics_title)\n",
    "    \n",
    "    if sizes_sd < lowest_sd and min(topic_sizes) >= min_size:\n",
    "      lowest_sd_iteration = i\n",
    "      lowest_sd = sizes_sd\n",
    "      \n",
    "  # Set the chosen partitioning to be the one with highest modularity\n",
    "  topics_title = topics_title_accepted[lowest_sd_iteration]\n",
    "  print(f'Best SD: {lowest_sd}, Best iteration: {lowest_sd_iteration}')\n",
    "  \n",
    "  topic_id_means = [sum(e)/len(e) for e in topics_title]\n",
    "  # Arrange title_topics in order of topic_id_means\n",
    "  topics_title = [list(c) for _, c in sorted(zip(topic_id_means, topics_title), key = lambda pair: pair[0])]\n",
    "  # Create an array denoting which topic each chunk belongs to\n",
    "  chunk_topics = [None] * title_similarity.shape[0]\n",
    "  for i, c in enumerate(topics_title):\n",
    "    for j in c:\n",
    "      chunk_topics[j] = i\n",
    "            \n",
    "  return {\n",
    "    'chunk_topics': chunk_topics,\n",
    "    'topics': topics_title\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_stage_2(stage_1_outputs, topics, summary_num_words = 250):\n",
    "  print(f'Stage 2 start time {datetime.now()}')\n",
    "  \n",
    "  # Prompt that passes in all the titles of a topic, and asks for an overall title of the topic\n",
    "  title_prompt_template = \"\"\"Write an informative title that summarizes each of the following groups of titles. Make sure that the titles capture as much information as possible, \n",
    "  and are different from each other:\n",
    "  {text}\n",
    "  \n",
    "  Return your answer in a numbered list, with new line separating each title: \n",
    "  1. Title 1\n",
    "  2. Title 2\n",
    "  3. Title 3\n",
    "\n",
    "  TITLES:\n",
    "  \"\"\"\n",
    "\n",
    "#   map_prompt_template = \"\"\"Wite a 75-100 word summary of the following text:\n",
    "#     {text}\n",
    "\n",
    "#     CONCISE SUMMARY:\"\"\"\n",
    "\n",
    "# Use less word to try solve the warning/error:\n",
    "# Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). \n",
    "# Running this sequence through the model will result in indexing errors\n",
    "  map_prompt_template = \"\"\"Wite a 75-85 word summary of the following text:\n",
    "      {text}\n",
    "\n",
    "      CONCISE SUMMARY:\"\"\"\n",
    "    \n",
    "\n",
    "  combine_prompt_template = 'Write a ' + str(summary_num_words) + \"\"\"-word summary of the following, removing irrelevant information. Finish your answer:\n",
    "  {text}\n",
    "  \"\"\" + str(summary_num_words) + \"\"\"-WORD SUMMARY:\"\"\"\n",
    "\n",
    "  title_prompt = PromptTemplate(template=title_prompt_template, input_variables=[\"text\"])\n",
    "  map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "  combine_prompt = PromptTemplate(template=combine_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "  topics_data = []\n",
    "  for c in topics:\n",
    "    topic_data = {\n",
    "      'summaries': [stage_1_outputs[chunk_id]['summary'] for chunk_id in c],\n",
    "      'titles': [stage_1_outputs[chunk_id]['title'] for chunk_id in c]\n",
    "    }\n",
    "    topic_data['summaries_concat'] = ' '.join(topic_data['summaries'])\n",
    "    topic_data['titles_concat'] = ', '.join(topic_data['titles'])\n",
    "    topics_data.append(topic_data)\n",
    "    \n",
    "  # Get a list of each community's summaries (concatenated)\n",
    "  topics_summary_concat = [c['summaries_concat'] for c in topics_data]\n",
    "  topics_titles_concat = [c['titles_concat'] for c in topics_data]\n",
    "\n",
    "  # Concat into one long string to do the topic title creation\n",
    "  topics_titles_concat_all = ''''''\n",
    "  for i, c in enumerate(topics_titles_concat):\n",
    "    topics_titles_concat_all += f'''{i+1}. {c}\n",
    "    '''\n",
    "  \n",
    "  # print('topics_titles_concat_all', topics_titles_concat_all)\n",
    "\n",
    "  title_llm = ChatOllama(model=\"openchat\")\n",
    "  title_llm_chain = LLMChain(llm = title_llm, prompt = title_prompt)\n",
    "  title_llm_chain_input = [{'text': topics_titles_concat_all}]\n",
    "  title_llm_chain_results = title_llm_chain.apply(title_llm_chain_input)\n",
    "  \n",
    "  \n",
    "  # Split by new line\n",
    "  titles = title_llm_chain_results[0]['text'].split('\\n')\n",
    "  # Remove any empty titles\n",
    "  titles = [t for t in titles if t != '']\n",
    "  # Remove spaces at start or end of each title\n",
    "  titles = [t.strip() for t in titles]\n",
    "\n",
    "  map_llm = ChatOllama(model=\"openchat\")\n",
    "  reduce_llm = ChatOllama(model=\"openchat\")\n",
    "\n",
    "  # Run the map-reduce chain\n",
    "  docs = [Document(page_content=t) for t in topics_summary_concat]\n",
    "  chain = load_summarize_chain(chain_type=\"map_reduce\", map_prompt = map_prompt, combine_prompt = combine_prompt, return_intermediate_steps = True,\n",
    "                              llm = map_llm, reduce_llm = reduce_llm)\n",
    "\n",
    "  output = chain({\"input_documents\": docs}, return_only_outputs = True)\n",
    "  summaries = output['intermediate_steps']\n",
    "  stage_2_outputs = [{'title': t, 'summary': s} for t, s in zip(titles, summaries)]\n",
    "  final_summary = output['output_text']\n",
    "\n",
    "  # Return: stage_1_outputs (title and summary), stage_2_outputs (title and summary), final_summary, chunk_allocations\n",
    "  out = {\n",
    "    'stage_2_outputs': stage_2_outputs,\n",
    "    'final_summary': final_summary\n",
    "  }\n",
    "  print(f'Stage 2 done time {datetime.now()}')\n",
    "  \n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode_name: Life 3.0, is_technical: no\n",
      "episode_name: Consciousness, is_technical: no\n",
      "episode_name: AI in the Age of Reason, is_technical: yes\n",
      "episode_name: Deep Learning, is_technical: yes\n",
      "episode_name: Statistical Learning, is_technical: Yes\n",
      "episode_name: Python, is_technical: no\n",
      "episode_name: Stack Overflow and Coding Horror, is_technical: yes\n",
      "episode_name: Google, is_technical: no\n",
      "episode_name: Long-Term Future of Artificial Intelligence, is_technical: no\n",
      "episode_name: Deep Reinforcement Learning, is_technical: yes\n",
      "episode_name: Godel Machines, Meta-Learning, and LSTMs, is_technical: Yes\n",
      "episode_name: Poker and Game Theory, is_technical: no\n",
      "episode_name: Brains, Minds, and Machines, is_technical: no\n",
      "episode_name: Cruise Automation, is_technical: no\n",
      "episode_name: Reinforcement Learning, Planning, and Robotics, is_technical: yes\n",
      "episode_name: Revolutionary Ideas in Science, Math, and Society, is_technical: no\n",
      "episode_name: OpenAI and AGI, is_technical: no\n",
      "episode_name: Tesla Autopilot, is_technical: yes\n",
      "episode_name: Generative Adversarial Networks (GANs), is_technical: yes\n",
      "episode_name: DeepMind AlphaStar, StarCraft, and Language, is_technical: yes\n",
      "episode_name: Compilers, LLVM, Swift, TPU, and ML Accelerators, is_technical: Yes\n",
      "episode_name: TensorFlow, is_technical: Yes\n",
      "episode_name: Adobe Research, is_technical: Yes\n",
      "episode_name: Affective Computing, Emotion, Privacy, and Health, is_technical: yes\n",
      "episode_name: Thousand Brains Theory of Intelligence, is_technical: no\n",
      "episode_name: The Nature of the Universe, Life, and Intelligence, is_technical: no\n",
      "episode_name: AI Superpowers - China and Silicon Valley, is_technical: yes\n",
      "episode_name: Self-Driving Cars at Aurora, Google, CMU, and DARPA, is_technical: yes\n",
      "episode_name: Spotify, is_technical: no\n",
      "episode_name: Microsoft CTO, is_technical: no\n",
      "episode_name: Comma.ai, OpenPilot, and Autonomous Vehicles, is_technical: Yes\n",
      "episode_name: Brain Development from Stem Cell to Organoid, is_technical: no\n",
      "episode_name: Lockheed Martin, is_technical: no\n",
      "episode_name: Machines Who Think and the Early Days of AI, is_technical: Yes\n",
      "episode_name: fast.ai Deep Learning Courses and Research, is_technical: yes\n",
      "episode_name: Deep Learning, ConvNets, and Self-Supervised Learning, is_technical: yes\n",
      "episode_name: Flying Robots, is_technical: no\n",
      "episode_name: Keras, Deep Learning, and the Progress of AI, is_technical: yes\n",
      "episode_name: iRobot CEO, is_technical: no\n",
      "episode_name: Deep Learning for Cancer Diagnosis and Treatment, is_technical: Yes\n",
      "episode_name: Quantum Mechanics, String Theory and Black Holes, is_technical: yes\n",
      "episode_name: Artificial Intelligence: A Modern Approach, is_technical: Yes\n",
      "episode_name: Toward a Hybrid of Deep Learning and Symbolic AI, is_technical: yes\n",
      "episode_name: IBM Watson, Jeopardy & Deep Conversations with AI, is_technical: yes\n",
      "episode_name: Future of Humans, Aliens, Space Travel & Physics, is_technical: no\n",
      "episode_name: Chess, Deep Blue, AI, and Putin, is_technical: no\n",
      "episode_name: Quantum Mechanics and the Many-Worlds Interpretation, is_technical: yes\n",
      "episode_name: C++, is_technical: Yes\n",
      "episode_name: Neuralink, AI, Autopilot, and the Pale Blue Dot, is_technical: yes\n",
      "episode_name: Algorithmic Fairness, Privacy & Ethics, is_technical: yes\n",
      "episode_name: Space Exploration, Space Suits, and Life on Mars, is_technical: no\n",
      "episode_name: Linear Algebra, Teaching, and MIT OpenCourseWare, is_technical: yes\n",
      "episode_name: Language, Cognition, and Deep Learning, is_technical: yes\n",
      "episode_name: Principles, the Economic Machine, AI & the Arc of Life, is_technical: no\n",
      "episode_name: Comedy, Robotics, Neurology, and Love, is_technical: no\n",
      "episode_name: Causal Reasoning, Counterfactuals, and the Path to AGI, is_technical: Yes\n",
      "episode_name: Amazon Alexa and Conversational AI, is_technical: yes\n",
      "episode_name: Vsauce, is_technical: no\n",
      "episode_name: Flying Cars, Autonomous Vehicles, and Education, is_technical: no\n",
      "episode_name: Supersymmetry, String Theory and Proving Einstein Right, is_technical: yes\n",
      "episode_name: Concepts, Analogies, Common Sense & Future of AI, is_technical: yes\n",
      "episode_name: Algorithms, Complexity, and The Art of Computer Programming, is_technical: Yes\n",
      "episode_name: Stalin, Putin, and the Nature of Power, is_technical: no\n",
      "episode_name: 3Blue1Brown and the Beauty of Mathematics, is_technical: yes\n",
      "episode_name: Thinking Fast and Slow, Deep Learning, and AI, is_technical: no\n",
      "episode_name: Human-Robot Interaction & Ethics of Safety-Critical Systems, is_technical: yes\n",
      "episode_name: Economics of Innovation, Automation, Safety Nets & UBI, is_technical: no\n",
      "episode_name: YouTube Algorithm, is_technical: Yes\n",
      "episode_name: The Hard Problem of Consciousness, is_technical: no\n",
      "episode_name: Moore's Law, Microprocessors, and First Principles, is_technical: yes\n",
      "episode_name: Predicates, Invariants, and the Essence of Intelligence, is_technical: yes\n",
      "episode_name: Quantum Computing, is_technical: yes\n",
      "episode_name: Deep Learning, Education, and Real-World AI, is_technical: yes\n",
      "episode_name: Machine Learning, Recommender Systems, and Future of AI, is_technical: yes\n",
      "episode_name: Universal Artificial Intelligence, AIXI, and AGI, is_technical: yes\n",
      "episode_name: Physics View of the Mind and Neurobiology, is_technical: yes\n",
      "episode_name: Ex Machina, Devs, Annihilation, and the Poetry of Science, is_technical: no\n",
      "episode_name: Cosmos, Carl Sagan, Voyager, and the Beauty of Science, is_technical: no\n",
      "episode_name: Quantum Gravity and Einstein's Unfinished Revolution, is_technical: yes\n",
      "episode_name: Ethereum, Cryptocurrency, and the Future of Money, is_technical: yes\n",
      "episode_name: Human-Robot Interaction and Reward Engineering, is_technical: yes\n",
      "episode_name: Leadership, Hard Work, Optimism and the Infinite Game, is_technical: no\n",
      "episode_name: Simulation and Superintelligence, is_technical: yes\n",
      "episode_name: Effective Altruism, is_technical: no\n",
      "episode_name: Physics of Consciousness and the Infinite Universe, is_technical: yes\n",
      "episode_name: AlphaGo, AlphaZero, and Deep Reinforcement Learning, is_technical: yes\n",
      "episode_name: Evolution, Intelligence, Simulation, and Memes, is_technical: no\n",
      "episode_name: Geometric Unity and the Call for New Ideas & Institutions, is_technical: no\n",
      "episode_name: Cellular Automata, Computation, and Physics, is_technical: Yes\n",
      "episode_name: Computational Biology of Coronavirus, is_technical: no\n",
      "episode_name: Square, Cryptocurrency, and Artificial Intelligence, is_technical: yes\n",
      "episode_name: Particle Physics and the Large Hadron Collider, is_technical: yes\n",
      "episode_name: Biomedicine and Machine Learning, is_technical: Yes\n",
      "episode_name: Deep Learning, is_technical: yes\n",
      "episode_name: Adversarial Machine Learning and Computer Security, is_technical: yes\n",
      "episode_name: Going Big in Business, Investing, and AI, is_technical: no\n",
      "episode_name: Robots That Fly and Robots That Drive, is_technical: yes\n",
      "episode_name: Social Robotics, is_technical: Yes\n",
      "episode_name: Neuroscience and the Free Energy Principle, is_technical: no\n",
      "episode_name: Artificial Consciousness and the Nature of Reality, is_technical: no\n",
      "episode_name: The War of Art, is_technical: no\n",
      "episode_name: Artificial General Intelligence, is_technical: yes\n",
      "episode_name: Computer Architecture and Data Storage, is_technical: yes\n",
      "episode_name: Edison of Medicine, is_technical: no\n",
      "episode_name: Neuroscience, Psychology, and AI at DeepMind, is_technical: no\n",
      "episode_name: Suffering in Humans, Animals, and AI, is_technical: no\n",
      "episode_name: Robotics and Machine Learning, is_technical: yes\n",
      "episode_name: UNIX, C, AWK, AMPL, and Go Programming, is_technical: yes\n",
      "episode_name: Computer Vision, is_technical: yes\n",
      "episode_name: Algorithms and Computational Complexity, is_technical: yes\n",
      "episode_name: Nuclear Fusion, Plasma Physics, and Religion, is_technical: yes\n",
      "episode_name: Human Genome and Evolutionary Dynamics, is_technical: yes\n",
      "episode_name: Underactuated Robotics, Control, Dynamics and Touch, is_technical: yes\n",
      "episode_name: Brain-Inspired AI, is_technical: yes\n",
      "episode_name: Search for Planets and Life Outside Our Solar System, is_technical: no\n",
      "episode_name: Death and Meaning, is_technical: no\n",
      "episode_name: Math, Manim, Neural Networks & Teaching with 3Blue1Brown, is_technical: yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode_name: Neuroplasticity and the Livewired Brain, is_technical: yes\n",
      "episode_name: Measures of Intelligence, is_technical: no\n",
      "episode_name: Friendship with an AI Companion, is_technical: no\n",
      "episode_name: UFOs, Aliens, Fighter Jets, and Aerospace Engineering, is_technical: no\n",
      "episode_name: Origin of Life, Humans, Ideas, Suffering, and Happiness, is_technical: no\n",
      "episode_name: Fundamental Theory of Physics, Life, and the Universe, is_technical: no\n",
      "episode_name: Martial Arts and the Philosophy of Violence, Power, and Grace, is_technical: no\n",
      "episode_name: Java, JVM, Emacs, and the Early Days of Computing, is_technical: yes\n",
      "episode_name: Fear, Love, Chaos, and the Joe Rogan Experience, is_technical: no\n",
      "episode_name: Anarchy, Democracy, Libertarianism, Love, and Trolling, is_technical: no\n",
      "episode_name: Counterintuitive Ideas About How the Brain Works, is_technical: no\n",
      "episode_name: Computational Complexity and Consciousness, is_technical: no\n",
      "episode_name: The Future of Computing and Programming Languages, is_technical: Yes\n",
      "episode_name: Hacking the Simulation & Learning to Drive with Neural Nets, is_technical: yes\n",
      "episode_name: Biology of Disease, is_technical: no\n",
      "episode_name: On the Nature of Good and Evil, Genius and Madness, is_technical: no\n",
      "episode_name: Computing, Interactive AI, and Race in America, is_technical: no\n",
      "episode_name: Hardcore History, is_technical: no\n",
      "episode_name: Supernovae, Dark Energy, Aliens & the Expanding Universe, is_technical: yes\n",
      "episode_name: Ayn Rand and the Philosophy of Objectivism, is_technical: no\n",
      "episode_name: Neuroscience of Optimal Performance, is_technical: no\n",
      "episode_name: Love, Evolution, and the Human Brain, is_technical: no\n",
      "episode_name: Economics of AI, Social Networks, and Technology, is_technical: yes\n",
      "episode_name: Meaning of Life, the Universe, and Everything, is_technical: no\n",
      "episode_name: The Art of Fighting and the Pursuit of Excellence, is_technical: no\n",
      "episode_name: Reinforcement Learning and the Future of AI, is_technical: Yes\n",
      "episode_name: Psychedelics, is_technical: no\n",
      "episode_name: Rapid Testing, Viruses, and the Engineering Mindset, is_technical: yes\n",
      "episode_name: Waymo and the Future of Self-Driving Cars, is_technical: Yes\n",
      "episode_name: Machine Learning and Education, is_technical: Yes\n",
      "episode_name: Aliens, Technology, Religion & the Nature of Belief, is_technical: no\n",
      "episode_name: The White Pill, Freedom, Hope, and Happiness Amidst Chaos, is_technical: no\n",
      "episode_name: Speech Recognition with AI and Humans, is_technical: yes\n",
      "episode_name: Olympic Wrestling, Mental Toughness & the Making of Champions, is_technical: no\n",
      "episode_name: Evolution of Proteins, Viruses, Life, and AI, is_technical: Yes\n",
      "episode_name: Aliens, Black Holes, and the Mystery of the Oumuamua, is_technical: no\n",
      "episode_name: AI and Physics, is_technical: yes\n",
      "episode_name: Comedy, Power, Conspiracy Theories, and Freedom, is_technical: no\n",
      "episode_name: Rocket Engines and Electric Spacecraft Propulsion, is_technical: yes\n",
      "episode_name: The Next Generation of Big Ideas and Brave Minds, is_technical: no\n",
      "episode_name: WallStreetBets, Numerai, and the Future of Stock Trading, is_technical: no\n",
      "episode_name: JavaScript, Firefox, Mozilla, and Brave, is_technical: yes\n",
      "episode_name: Startups, Angel Investing, Capitalism, and Friendship, is_technical: no\n",
      "episode_name: The Future of Computing, AI, Life, and Consciousness, is_technical: yes\n",
      "episode_name: Difficult Conversations, Freedom of Speech, and Physics, is_technical: no\n",
      "episode_name: Sleep, Dreams, Creativity, Fasting, and Neuroplasticity, is_technical: no\n",
      "episode_name: Philosophy of Violence, Power, and the Martial Arts, is_technical: yes\n",
      "episode_name: Deep Work, Focus, Productivity, Email, and Social Media, is_technical: no\n",
      "episode_name: Politics, History, and Power, is_technical: no\n",
      "episode_name: Cryptocurrency, Blockchain, Algorand, Bitcoin & Ethereum, is_technical: yes\n",
      "episode_name: Solving Martial Arts from First Principles, is_technical: no\n",
      "episode_name: The Ideal of Justice in the Face of Controversy and Evil, is_technical: no\n",
      "episode_name: Bitcoin, is_technical: no\n",
      "episode_name: Librex and the Free Exchange of Ideas on College Campuses, is_technical: no\n",
      "episode_name: Bitcoin Core Values, Layered Scaling, and Blocksize Debates, is_technical: yes\n",
      "episode_name: Economic Growth & the Fight Against Conformity & Mediocrity, is_technical: no\n",
      "episode_name: History and Comedy, is_technical: no\n",
      "episode_name: Philosophy of Bitcoin from First Principles, is_technical: no\n",
      "episode_name: Neuroevolution and Evolutionary Computation, is_technical: yes\n",
      "episode_name: Ayn Rand, Human Nature, and Anarchy, is_technical: no\n",
      "episode_name: The Science of Fighting, is_technical: no\n",
      "episode_name: History of American Power, is_technical: no\n",
      "episode_name: Chainlink, Smart Contracts, and Oracle Networks, is_technical: yes\n",
      "episode_name: The Path to Mastery in Jiu Jitsu, Grappling, Judo, and MMA, is_technical: yes\n",
      "episode_name: Mathematics, Math Olympiad, Combinatorics & Contact Tracing, is_technical: yes\n",
      "episode_name: Planets, Moons, Asteroids & Life in Our Solar System, is_technical: no\n",
      "episode_name: Consciousness, Free Will, Psychedelics, AI, UFOs, and Meaning, is_technical: no\n",
      "episode_name: Kernel Brain-Computer Interfaces, is_technical: Yes\n",
      "episode_name: Physics of Quarks, Dark Matter, Complexity, Life & Aliens, is_technical: Yes\n",
      "episode_name: Ethereum 2.0, is_technical: yes\n",
      "episode_name: Extending the Human Lifespan Beyond 100 Years, is_technical: no\n",
      "episode_name: Mathematics of High-Dimensional Shapes and Geometries, is_technical: yes\n",
      "episode_name: Steering Civilization Away from Self-Destruction, is_technical: no\n",
      "episode_name: Cardano, is_technical: no\n",
      "episode_name: The Existential Threat of Engineered Viruses and Lab Leaks, is_technical: yes\n",
      "episode_name: Truth, Science, and Censorship in the Time of a Pandemic, is_technical: no\n",
      "episode_name: Searching for Signs of Life on Venus and Other Planets, is_technical: no\n",
      "episode_name: North Korea, is_technical: no\n",
      "episode_name: War, Leadership, and Discipline, is_technical: no\n",
      "episode_name: The Origin of Life on Earth and Alien Worlds, is_technical: no\n",
      "episode_name: Smuggling Drugs for Pablo Escobar and the Medellin Cartel, is_technical: no\n",
      "episode_name: Totalitarianism and Anarchy, is_technical: no\n",
      "episode_name: Planet 9 and the Edge of Our Solar System, is_technical: no\n",
      "episode_name: Psychedelics, is_technical: no\n",
      "episode_name: Regenerative Farming and the Art of Cooking Meat, is_technical: no\n",
      "episode_name: String Theory, is_technical: no\n",
      "episode_name: Ultramarathon Running, is_technical: no\n",
      "episode_name: Self-Supervised Deep Learning in Computer Vision, is_technical: yes\n",
      "episode_name: The Mad Scientist of Strength, is_technical: no\n",
      "episode_name: The Thousand Brains Theory of Intelligence, is_technical: no\n",
      "episode_name: Fermat's Library and the Art of Studying Papers, is_technical: no\n",
      "episode_name: Sleep, is_technical: no\n",
      "episode_name: The Secret History of Psychedelics, is_technical: no\n",
      "episode_name: Nature of Reality, Dreams, and Consciousness, is_technical: no\n",
      "episode_name: Gravitational Waves and the Most Precise Device Ever Built, is_technical: yes\n",
      "episode_name: Isaac Newton and the Philosophy of Science, is_technical: no\n",
      "episode_name: OpenAI Codex, GPT-3, Robotics, and the Future of AI, is_technical: yes\n",
      "episode_name: Viruses and Vaccines, is_technical: no\n",
      "episode_name: Robotics, is_technical: no\n",
      "episode_name: Virtual Reality, Social Media & the Future of Humans and AI, is_technical: yes\n",
      "episode_name: Programming, Algorithms, Hard Problems & the Game of Life, is_technical: Yes\n",
      "episode_name: New York Firefighters and the Heroes of 9/11, is_technical: no\n",
      "episode_name: Cyc and the Quest to Solve Common Sense Reasoning in AI, is_technical: yes\n",
      "episode_name: Neural Networks and the Emergence of Cognition, is_technical: yes\n",
      "episode_name: Judo, Olympics, and Mental Toughness, is_technical: no\n",
      "episode_name: NumPy, SciPy, Anaconda, Python & Scientific Programming, is_technical: Yes\n",
      "episode_name: Neuromorphic Computing and Optoelectronic Intelligence, is_technical: yes\n",
      "episode_name: How to Learn Math, is_technical: no\n",
      "episode_name: Existentialism, Nihilism, and the Search for Meaning, is_technical: no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode_name: Wu-Tang Clan, Kung Fu, Chess, God, Life, and Death, is_technical: no\n",
      "episode_name: Violence, Sex, and Fire in Human Evolution, is_technical: no\n",
      "episode_name: War, Artillery, PTSD, and Love, is_technical: no\n",
      "episode_name: Bitcoin, Authoritarianism, and Human Rights, is_technical: no\n",
      "episode_name: Quantum Gravity, The Big Bang, Aliens, Death, and Meaning, is_technical: no\n",
      "episode_name: Heroin, Cocaine, MDMA, Alcohol & the Role of Drugs in Society, is_technical: no\n",
      "episode_name: Complexity and the Fabric of Reality, is_technical: no\n",
      "episode_name: Rapid COVID Testing, is_technical: no\n",
      "episode_name: Judo and the Forging of Champions, is_technical: no\n",
      "episode_name: Trucking and the Decline of the American Dream, is_technical: no\n",
      "episode_name: National Institutes of Health (NIH), is_technical: no\n",
      "episode_name: History of Money, Power, War, and Truth, is_technical: no\n",
      "episode_name: Sci-Fi, Space, Aliens, AI, VR & the Future of Humanity, is_technical: no\n",
      "episode_name: Waymo, Cozmo, Self-Driving Cars, and the Future of Robotics, is_technical: Yes\n",
      "episode_name: Wrestling and MMA, is_technical: no\n",
      "episode_name: Instagram, is_technical: no\n",
      "episode_name: Afghanistan, Taliban, Bin Laden, and War in the Middle East, is_technical: no\n",
      "episode_name: Iowa Wrestling, is_technical: no\n",
      "episode_name: Theories of Everything & Why String Theory is Not Even Wrong, is_technical: yes\n",
      "episode_name: Lab Leak Theory, is_technical: no\n",
      "episode_name: Genocide, Stalin, Hitler, Mao, and Absolute Power, is_technical: no\n",
      "episode_name: Pfizer CEO, is_technical: no\n",
      "episode_name: Python and the Source Code of Humans, Computers, and Reality, is_technical: no\n",
      "episode_name: Money, Power, and the Collapse of Empires, is_technical: no\n",
      "episode_name: SpaceX, Mars, Tesla Autopilot, Self-Driving, Robotics, and AI, is_technical: no\n",
      "episode_name: New Year's Special, is_technical: no\n",
      "episode_name: The Case Against Lockdowns, is_technical: no\n",
      "episode_name: Comedy!, is_technical: no\n",
      "episode_name: Yaron Brook and Yoram Hazony, is_technical: no\n",
      "episode_name: Cosmology, Astrophysics, Aliens & Losing the Nobel Prize, is_technical: no\n",
      "episode_name: Dark Matter of Intelligence and Self-Supervised Learning, is_technical: yes\n",
      "episode_name: From Batman Dark Knight Trilogy to AI and The Rolling Stones, is_technical: no\n",
      "episode_name: The Greatest of All Time, is_technical: no\n",
      "episode_name: Consciousness, Panpsychism, and the Philosophy of Mind, is_technical: no\n",
      "episode_name: UFOs and Aliens, is_technical: no\n",
      "episode_name: Big Pharma, is_technical: no\n",
      "episode_name: Elon Musk, Neuralink, AI, Aliens, and the Future of Humanity, is_technical: no\n",
      "episode_name: Arm Wrestling, is_technical: no\n",
      "episode_name: Cybersecurity and the Weapons of Cyberwar, is_technical: Yes\n",
      "episode_name: Meta, Facebook, Instagram, and the Metaverse, is_technical: yes\n",
      "episode_name: Origin of Life, Aliens, Complexity, and Consciousness, is_technical: no\n",
      "episode_name: Judaism, is_technical: no\n",
      "episode_name: Space Colonization and Self-Assembling Space Megastructures, is_technical: no\n",
      "episode_name: US Most Wanted Cybercriminal, is_technical: no\n",
      "episode_name: War and Violence, is_technical: no\n",
      "episode_name: Depression, Schizophrenia, and Psychiatry, is_technical: no\n",
      "episode_name: Legendary Music Producer, is_technical: no\n",
      "episode_name: Bitcoin, Inflation, and the Future of Money, is_technical: Yes\n",
      "episode_name: Focus, Stress, Relationships, and Friendship, is_technical: no\n",
      "episode_name: Hunger, War, and Human Suffering, is_technical: no\n",
      "episode_name: Sara Walker and Lee Cronin, is_technical: no\n",
      "episode_name: Qualcomm CEO, is_technical: no\n",
      "episode_name: Music, AI, and the Future of Humanity, is_technical: yes\n",
      "episode_name: Bitcoin, Anarchy, and Austrian Economics, is_technical: no\n",
      "episode_name: Race, Racism, Identity Politics, and Cancel Culture, is_technical: no\n",
      "episode_name: Vladimir Putin and War in Ukraine, is_technical: no\n",
      "episode_name: Bad Vegan, Fraud, Prison, and Sociopathy, is_technical: no\n",
      "episode_name: Putin, Stalin, Hitler, Zelenskyy, and War in Ukraine, is_technical: no\n",
      "episode_name: Imagine Dragons, is_technical: no\n",
      "episode_name: Alien Civilizations, UFOs, and the Future of Humanity, is_technical: no\n",
      "episode_name: Reality is an Illusion - How Evolution Hid the Truth, is_technical: no\n",
      "episode_name: iPhone, iPod, Nest, Steve Jobs, Design, and Engineering, is_technical: Yes\n",
      "episode_name: Marxism and Communism, is_technical: no\n",
      "episode_name: Racism, Marxism, and the War on the West, is_technical: no\n",
      "episode_name: The Human Body - From Sex & Sperm to Hands & Heart, is_technical: no\n",
      "episode_name: The Power of Introverts and Loneliness, is_technical: no\n",
      "episode_name: DeepMind - AI, Superintelligence & the Future of Humanity, is_technical: yes\n",
      "episode_name: Comedy, Controversy, Aliens, UFOs, Putin, CIA, and Freedom, is_technical: no\n",
      "episode_name: KGB Spy, is_technical: no\n",
      "episode_name: IQ Tests, Human Intelligence, and Group Differences, is_technical: no\n",
      "episode_name: Marxism, Capitalism, and Economics, is_technical: no\n",
      "episode_name: Christianity and the Catholic Church, is_technical: no\n",
      "episode_name: Black Holes, Alien Life, Dark Matter, and the Big Bang, is_technical: no\n",
      "episode_name: Deep Learning and Artificial General Intelligence, is_technical: yes\n",
      "episode_name: Coinbase, Cryptocurrency, and Government Regulation, is_technical: no\n",
      "episode_name: UFOs, Fighter Jets, and Aliens, is_technical: no\n",
      "episode_name: Doom, Quake, VR, AGI, Programming, Video Games, and Rockets, is_technical: Yes\n",
      "episode_name: CIA Spy, is_technical: no\n",
      "episode_name: Africa, Capitalism, Communism, and the Future of Humanity, is_technical: no\n",
      "episode_name: Comedy, Sentient Robots, Suffering, Love & Burning Man, is_technical: no\n",
      "episode_name: Life, Death, Power, Fame, and Meaning, is_technical: no\n",
      "episode_name: Poker, Game Theory, AI, Simulation, Aliens & Existential Risk, is_technical: yes\n",
      "episode_name: Greatest Chess Player of All Time, is_technical: no\n",
      "episode_name: Putin, Ukraine, China, and Nuclear War, is_technical: no\n",
      "episode_name: Meaning Crisis, Atheism, Religion & the Search for Wisdom, is_technical: no\n",
      "episode_name: Origin of Life, Evolution, Aliens, Biology, and Consciousness, is_technical: yes\n",
      "episode_name: Chess, Streaming, and Fame, is_technical: no\n",
      "episode_name: World War I, Ideology, Propaganda, and Politics, is_technical: no\n",
      "episode_name: Singularity, Superintelligence, and Immortality, is_technical: no\n",
      "episode_name: Emotion AI, Social Robots, and Self-Driving Cars, is_technical: yes\n",
      "episode_name: Comedy, MADtv, AI, Friendship, Madness, and Pro Wrestling, is_technical: no\n",
      "episode_name: Poker, is_technical: no\n",
      "episode_name: Biology, Life, Aliens, Evolution, Embryogenesis & Xenobots, is_technical: no\n"
     ]
    }
   ],
   "source": [
    "def is_techincal_podcast_title(title):\n",
    "\n",
    "    eval_prompt_template = \"\"\"\n",
    "    Determine if the given title belongs to a technical podcast. \n",
    "    \n",
    "    Here is the Title: {title}\n",
    "    \n",
    "    Answer 'yes' if the title belongs to a technical podcast. Otherwise, answer 'no'.\n",
    "    Also, gives a reason for your answer.\n",
    "    \n",
    "    Your answer format should be:\n",
    "    yes/no | reason\n",
    "    \"\"\"\n",
    "    \n",
    "    eval_prompt = PromptTemplate(template=eval_prompt_template, input_variables=['title'])\n",
    "\n",
    "    # Define the LLMs\n",
    "    map_llm = ChatOllama(model=\"openchat\")\n",
    "\n",
    "    map_llm_chain = LLMChain(llm = map_llm, prompt = eval_prompt)\n",
    "\n",
    "    input_data = [\n",
    "        {\n",
    "            'title': title\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Run the input through the LLM chain (works in parallel)\n",
    "    map_llm_chain_results = map_llm_chain.apply(input_data)\n",
    "    \n",
    "    return map_llm_chain_results\n",
    "    \n",
    "\n",
    "is_techincal_answers = []    \n",
    "for podcast in podcast_data:\n",
    "    \n",
    "    # use LLM to determine if this episode_name is considered a 'technical podcast'\n",
    "    episode_name = podcast['episode_name']   \n",
    "    episode_number = podcast['episode_number'] \n",
    "    \n",
    "    result = is_techincal_podcast_title(episode_name)\n",
    "    \n",
    "#     print(result)\n",
    "    \n",
    "    result = result[0]['text'].split(\"|\")\n",
    "    \n",
    "    answer = {\n",
    "        \"episode_number\": episode_number,\n",
    "        \"is_technical\" : result[0].strip(),\n",
    "        \"reason\": result[1].strip()\n",
    "    }\n",
    "    \n",
    "#     print(answer)\n",
    "\n",
    "    print(f\"episode_name: {episode_name}, is_technical: {answer['is_technical']}\")\n",
    "    is_techincal_answers.append(answer)    \n",
    "\n",
    "with open(f\"./summarized_dataset/check_is_techincal_podcast.json\", \"w\") as outfile: \n",
    "    json.dump(is_techincal_answers, outfile)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2024-02-25 15:23:57.620709\n",
      "Stage 1 done time 2024-02-25 15:25:54.732168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bizon/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SD: 1.984313483298443, Best iteration: 7\n",
      "Stage 2 start time 2024-02-25 15:25:58.039061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bizon/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/bizon/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 done time 2024-02-25 15:26:23.800103\n",
      "Start time: 2024-02-25 15:26:23.816819\n",
      "Stage 1 done time 2024-02-25 15:28:01.802417\n",
      "Best SD: 1.676305461424021, Best iteration: 25\n",
      "Stage 2 start time 2024-02-25 15:28:07.875843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 done time 2024-02-25 15:28:36.292122\n",
      "Start time: 2024-02-25 15:28:36.305633\n",
      "Stage 1 done time 2024-02-25 15:29:36.648161\n",
      "Best SD: 1.445683229480096, Best iteration: 1\n",
      "Stage 2 start time 2024-02-25 15:29:37.722654\n",
      "Stage 2 done time 2024-02-25 15:30:01.685771\n",
      "Start time: 2024-02-25 15:30:01.698208\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m chunks_text \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(podcast[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranscript\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Run Stage 1 Summarizing\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m stage_1_outputs \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_stage_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks_text\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstage_1_outputs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Split the titles and summaries\u001b[39;00m\n\u001b[1;32m     15\u001b[0m stage_1_summaries \u001b[38;5;241m=\u001b[39m [e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m stage_1_outputs]\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36msummarize_stage_1\u001b[0;34m(chunks_text)\u001b[0m\n\u001b[1;32m     22\u001b[0m map_llm_chain_input \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: t} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m chunks_text]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Run the input through the LLM chain (works in parallel)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m map_llm_chain_results \u001b[38;5;241m=\u001b[39m \u001b[43mmap_llm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap_llm_chain_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m stage_1_outputs \u001b[38;5;241m=\u001b[39m parse_title_summary_results([e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m map_llm_chain_results])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStage 1 done time \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain/chains/llm.py:227\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list, callbacks)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    226\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    228\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)\n\u001b[1;32m    229\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: outputs})\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain/chains/llm.py:224\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list, callbacks)\u001b[0m\n\u001b[1;32m    219\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    220\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    221\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_list},\n\u001b[1;32m    222\u001b[0m )\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    226\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain/chains/llm.py:115\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    123\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    124\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:544\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    538\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    543\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:408\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    407\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 408\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    409\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    410\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    412\u001b[0m ]\n\u001b[1;32m    413\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:398\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 398\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:577\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m     )\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_community/chat_models/ollama.py:255\u001b[0m, in \u001b[0;36mChatOllama._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    233\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    237\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     chat_generation \u001b[38;5;241m=\u001b[39m ChatGeneration(\n\u001b[1;32m    263\u001b[0m         message\u001b[38;5;241m=\u001b[39mAIMessage(content\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mtext),\n\u001b[1;32m    264\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mgeneration_info,\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[chat_generation])\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_community/chat_models/ollama.py:190\u001b[0m, in \u001b[0;36mChatOllama._chat_stream_with_aggregation\u001b[0;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_stream(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[0;32m--> 190\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m \u001b[43m_chat_stream_response_to_chat_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_chunk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m             final_chunk \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_community/chat_models/ollama.py:42\u001b[0m, in \u001b[0;36m_chat_stream_response_to_chat_generation_chunk\u001b[0;34m(stream_response)\u001b[0m\n\u001b[1;32m     40\u001b[0m parsed_response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(stream_response)\n\u001b[1;32m     41\u001b[0m generation_info \u001b[38;5;241m=\u001b[39m parsed_response \u001b[38;5;28;01mif\u001b[39;00m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mChatGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAIMessageChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparsed_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_core/load/serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/pydantic/main.py:1076\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/pydantic/fields.py:872\u001b[0m, in \u001b[0;36mpydantic.fields.ModelField.validate\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/pydantic/typing.py:355\u001b[0m, in \u001b[0;36mpydantic.typing.is_none_type\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/w210_podcast_ollama/lib/python3.11/typing.py:1706\u001b[0m, in \u001b[0;36m_LiteralGenericAlias.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_LiteralGenericAlias\u001b[39;00m(_GenericAlias, _root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 1706\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m   1707\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _LiteralGenericAlias):\n\u001b[1;32m   1708\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0YAAAA4CAYAAADZ5Og0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAPNUlEQVR4nO3dfVBU9b8H8PeyC8vqxTUgXFcE15kKhTJbUgkKpwfLxx5u/pISLR8SR0xkNDW7F6MxVCavUyhcvGk51GBdtNF8GMmUctCRAUx8SKxQESGyFBZFlt393j8Yz21lF9aFdRf2/Zr5zrTn8/18z/fYZ3b4zO6eIxNCCBAREREREXkxH3dvgIiIiIiIyN3YGBERERERkddjY0RERERERF6PjREREREREXk9NkZEREREROT12BgREREREZHXY2NERERERERej40RERERERF5PTZGRERERETk9dgYERERERGR13NZY3Tt2jUkJiZCrVZDrVYjMTER169f7zDnzTffhEwmsxpjxoxx1RaJiIiIiIgAAApXLfz666/j8uXL2L9/PwDg7bffRmJiInbv3t1h3gsvvICtW7dKr/38/Fy1RSIiIiIiIgAuaozOnj2L/fv349ixYxg9ejQAYPPmzYiJicG5c+fw0EMP2c1VKpXQaDSu2BYREREREZFNLmmMjh49CrVaLTVFADBmzBio1WoUFxd32BgdPnwYISEh6N+/P+Lj47F69WqEhITYnd/S0oKWlhbptcViwd9//42goCDIZLLuuSAiIiIiIupxhBAwGAzQarXw8en4V0QuaYzq6uqkZmbTpk3IzMxEbW0tgLam6a233rKZN378eERERGDbtm349ddfcfHiRezZswdVVVVQKpU2czIyMvDBBx+44jKIiIiIiKgXqK6uRmhoaIdzZEII4eiCq1at6rQJKSkpwYEDB/DFF18gPT0diYmJ2LRpE2JjYxETE4Pm5macP38eYWFh7XKrqqoQFRWFuXPnYt68edizZw+WLl2KJUuWIDMz0+b57vzEqKGhAWFhYRg0/3P4KPvYzPlz11rcP2VZt8a8ad3I3QnYPtX2vy0AvPbNTbtxV8S4bpstry/F/yzMw5xPp9uMOxvrSq6nndNV65r+61Fs+f5DzHr2P2zGnY11JdfTztmV3P8tWYb0ebPsrvuf/73FbtzZWE9bt6PYoZq/8M0332Dq1Kk2487GupLrLev+618BSEnZhg0bZtjMczbWlVxvWfco/h05KfORtCHbZp6zsa7kcl33rNvc1IQlT0Xj+vXrUKvVds8L3OUnRsnJyZg2bVqHc4YMGYKTJ0/ijz/+wPr16zF79mzMmTNHigcFBSE7OxsZGRntcnNychAWFoYNGzYAAIYNG4YPP/wQX3/9td3GSKlU2vw0yUfZx25jJPORd3vMm9b1lcvQT2n/a4odxV0R47ptVAH+kCvkUAX424w7G+tKrqed01Xrmvz6Qu6jgMqvr+1cJ2NdyfW0c3YlVyGXo69KZXfdjuLOxnrauh3FlEol5HK53W9eOBvrSq63rBsQ4A+FQo4AO+8dzsa6kust66pEAOQKBVT/FmAzz9lYV3K5rnvXdeQnNnfVGAUHByM4OLjTeTExMWhoaEBpaSlGjBgBnU6HK1euwGg0YvTo0SguLraZt2/fPvzyyy/tNt7U1ITW1lb4+vq2y7nzE6PGxsa7uSQiIiIiIiLXPMdo2LBhGDt2LMxmM7Zs2YKEhASEh4dDp9Ph8OHDqK6uBgBERERg586dANqan6qqKgDAwYMHUVBQAL1ej8DAQFgsFly9etXmuTIyMqRnJanVagwePNgVl0RERERERL2Yyx7wmpWVBaDtY6usrCyMGjUKZWVlUKvVaGhoAACcO3dO+m+5XI7W1lYAwPPPP4/FixcjKioKmzdvltaxZcWKFWhoaJDG7aaLiIiIiIjIUS57wGt4eDgAIDU1FWvXrpWOa7VaXLhwAUDb7fNuU6lUePDBB1FRUYHQ0FDcunUL1dXVOHXqFBQKBYKCghw67+01LS037c+xmO3GnY1507qtZoHGFvv37Ogo7ooY123TbLgFs8mMZsMtm3FnY13J9bRzumpdk/EGzBYTmo03bOc6GetKrqedsyu5JrMZN5qb7a7bUdzZWE9bt6NYS0sLzGaz1dfO/8nZWFdyvWVdg+EWTCYzDPbeO5yMdSXXW9ZthgFmkwnNTQabec7GupLLdd2zbnNTEwDrvsMu4SI1NTUCgHj55Zetjt9///0iMDDQZs7s2bOFRqMRpaWlori4WMyfP18AEMOHD7d7nrS0NAGAg4ODg4ODg4ODg4PD5qiuru60f7mr23XfjStXrmDQoEGQy+XIzc1FTEwMcnNzsXHjRgwePBi//fYbVqxYgZqaGmzbtg3A/9+ue968eZg7dy6OHj2KOXPmQK/Xo6SkxOZ5OnvAa2NjIwYPHozq6mr069fPFZdKXoB1RN2FtUTdgXVE3YF1RN3B0+tIuPsBr0DbHezkcjlmzZqF9PR01NbWIioqClOmTMGff/4JAKitrcWlS5ekHJ1Oh71792Lx4sXYuHEjtFotJk+ejMrKSrvnsXW77v79+7eb169fP4/8n0U9C+uIugtriboD64i6A+uIuoMn11Fnzy+6zWWNkZ+fH/R6PRQKhfSbIgAYPnw4XnzxRQDA559/3i4vPj4eZWVl0utXX30VAwcOdNU2iYiIiIiIXNcYAW03XkhMTER0dLT0VbpLly4hKSkJANp9lW7Dhg0YMmQIIiMjYTQakZeXh4KCAhQUFLhym0RERERE5OVc2hi99tpr+Ouvv6y+Srd3717pjnV3fpXOaDRiyZIlqKmpgUqlQmRkJPbs2YMJEyY4vQelUom0tLQOn1hN1BnWEXUX1hJ1B9YRdQfWEXWH3lRHLrv5AhERERERUU/hsge8EhERERER9RRsjIiIiIiIyOuxMSIiIiIiIq/HxoiIiIiIiLweGyMiIiIiIvJ6vb4x2rRpE3Q6Hfz9/aHX6/HTTz+5e0vkoTIyMvD4448jICAAISEheOmll3Du3DmrOUIIrFq1ClqtFiqVCmPHjsXp06fdtGPqCTIyMiCTyZCSkiIdYx2Ro2pqajB9+nQEBQWhT58+ePTRR1FaWirFWUvUGZPJhPfffx86nQ4qlQpDhw5Feno6LBaLNId1RLb8+OOPmDx5MrRaLWQyGb799luruCN109LSgoULFyI4OBh9+/bFlClTcPny5Xt4FXenVzdG27dvR0pKClauXIny8nI8+eSTGD9+vNWzk4huKyoqwoIFC3Ds2DEUFhbCZDJh3LhxuHHjhjRn3bp1WL9+PbKyslBSUgKNRoPnnnsOBoPBjTsnT1VSUoLc3Fw88sgjVsdZR+SIa9euITY2Fr6+vti3bx/OnDmDjz/+GP3795fmsJaoM2vXrkVOTg6ysrJw9uxZrFu3DpmZmfj000+lOawjsuXGjRsYMWIEsrKybMYdqZuUlBTs3LkT+fn5OHLkCJqamjBp0iSYzeZ7dRl3R/Rio0aNEklJSVbHIiIixPLly920I+pJ6uvrBQBRVFQkhBDCYrEIjUYj1qxZI825deuWUKvVIicnx13bJA9lMBjEAw88IAoLC0V8fLxYtGiREIJ1RI5btmyZiIuLsxtnLZEjJk6cKGbNmmV17JVXXhHTp08XQrCOyDEAxM6dO6XXjtTN9evXha+vr8jPz5fm1NTUCB8fH7F///57tve70Ws/MTIajSgtLcW4ceOsjo8bNw7FxcVu2hX1JA0NDQCAwMBAAEBVVRXq6uqsakqpVCI+Pp41Re0sWLAAEydOxLPPPmt1nHVEjtq1axeio6MxdepUhISEYOTIkdi8ebMUZy2RI+Li4nDw4EFUVlYCAH7++WccOXIEEyZMAMA6Iuc4UjelpaVobW21mqPVahEVFeWxtaVw9wZc5erVqzCbzRgwYIDV8QEDBqCurs5Nu6KeQgiB1NRUxMXFISoqCgCkurFVUxcvXrzneyTPlZ+fj7KyMpSUlLSLsY7IUb///juys7ORmpqK9957D8ePH8c777wDpVKJGTNmsJbIIcuWLUNDQwMiIiIgl8thNpuxevVqJCQkAOB7EjnHkbqpq6uDn58f7rvvvnZzPPVv8V7bGN0mk8msXgsh2h0julNycjJOnjyJI0eOtIuxpqgj1dXVWLRoEQ4cOAB/f3+781hH1BmLxYLo6Gh89NFHAICRI0fi9OnTyM7OxowZM6R5rCXqyPbt25GXl4evvvoKkZGROHHiBFJSUqDVajFz5kxpHuuInOFM3XhybfXar9IFBwdDLpe360jr6+vbdbdE/7Rw4ULs2rULhw4dQmhoqHRco9EAAGuKOlRaWor6+nro9XooFAooFAoUFRXhk08+gUKhkGqFdUSdGThwIIYPH251bNiwYdINhPieRI5YunQpli9fjmnTpuHhhx9GYmIiFi9ejIyMDACsI3KOI3Wj0WhgNBpx7do1u3M8Ta9tjPz8/KDX61FYWGh1vLCwEE888YSbdkWeTAiB5ORk7NixAz/88AN0Op1VXKfTQaPRWNWU0WhEUVERa4okzzzzDCoqKnDixAlpREdH44033sCJEycwdOhQ1hE5JDY2tt0jAyorKxEeHg6A70nkmJs3b8LHx/rPPblcLt2um3VEznCkbvR6PXx9fa3m1NbW4tSpU55bW2677cM9kJ+fL3x9fcVnn30mzpw5I1JSUkTfvn3FhQsX3L018kDz588XarVaHD58WNTW1krj5s2b0pw1a9YItVotduzYISoqKkRCQoIYOHCgaGxsdOPOydP98650QrCOyDHHjx8XCoVCrF69Wpw/f158+eWXok+fPiIvL0+aw1qizsycOVMMGjRIfPfdd6Kqqkrs2LFDBAcHi3fffVeawzoiWwwGgygvLxfl5eUCgFi/fr0oLy8XFy9eFEI4VjdJSUkiNDRUfP/996KsrEw8/fTTYsSIEcJkMrnrsjrUqxsjIYTYuHGjCA8PF35+fuKxxx6Tbr1MdCcANsfWrVulORaLRaSlpQmNRiOUSqV46qmnREVFhfs2TT3CnY0R64gctXv3bhEVFSWUSqWIiIgQubm5VnHWEnWmsbFRLFq0SISFhQl/f38xdOhQsXLlStHS0iLNYR2RLYcOHbL5d9HMmTOFEI7VTXNzs0hOThaBgYFCpVKJSZMmiUuXLrnhahwjE0II93xWRURERERE5Bl67W+MiIiIiIiIHMXGiIiIiIiIvB4bIyIiIiIi8npsjIiIiIiIyOuxMSIiIiIiIq/HxoiIiIiIiLweGyMiIiIiIvJ6bIyIiIiIiMjrsTEiIiIiIiKvx8aIiIiIiIi8HhsjIiIiIiLyev8H4VHcM0irgxQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "podcast_summary = []\n",
    "\n",
    "for podcast in podcast_data:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=900,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    chunks_text = text_splitter.split_text(podcast['transcript'])\n",
    "    \n",
    "    # Run Stage 1 Summarizing\n",
    "    stage_1_outputs = summarize_stage_1(chunks_text)['stage_1_outputs']\n",
    "    # Split the titles and summaries\n",
    "    stage_1_summaries = [e['summary'] for e in stage_1_outputs]\n",
    "    stage_1_titles = [e['title'] for e in stage_1_outputs]\n",
    "    num_1_chunks = len(stage_1_summaries)\n",
    "    \n",
    "    # Generate embeddings\n",
    "    summary_embeds = generate_embeddings(stage_1_summaries)\n",
    "#     title_embeds = generate_embeddings(stage_1_titles) # not used\n",
    "    \n",
    "    # Get similarity matrix between the embeddings of the chunk summaries\n",
    "    summary_similarity_matrix = np.zeros((num_1_chunks, num_1_chunks))\n",
    "    summary_similarity_matrix[:] = np.nan\n",
    "\n",
    "    for row in range(num_1_chunks):\n",
    "      for col in range(row, num_1_chunks):\n",
    "        # Calculate cosine similarity between the two vectors\n",
    "        similarity = 1- cosine(summary_embeds[row], summary_embeds[col])\n",
    "        summary_similarity_matrix[row, col] = similarity\n",
    "        summary_similarity_matrix[col, row] = similarity\n",
    "    \n",
    "    # Set num_topics to be 1/4 of the number of chunks, or 8, which ever is smaller\n",
    "    num_topics = min(int(num_1_chunks / 4), 8)\n",
    "    topics_out = get_topics(summary_similarity_matrix, num_topics = num_topics, bonus_constant = 0.2)\n",
    "    chunk_topics = topics_out['chunk_topics']\n",
    "    topics = topics_out['topics']\n",
    "    \n",
    "    # Plot a heatmap of this array\n",
    "    plt.figure(figsize = (10, 4))\n",
    "    plt.imshow(np.array(chunk_topics).reshape(1, -1), cmap = 'tab20')\n",
    "    # Draw vertical black lines for every 1 of the x-axis \n",
    "    for i in range(1, len(chunk_topics)):\n",
    "      plt.axvline(x = i - 0.5, color = 'black', linewidth = 0.5)\n",
    "    \n",
    "    # Query LLM to get a summarized title for each topic_data\n",
    "    out = summarize_stage_2(stage_1_outputs, topics, summary_num_words = 250)\n",
    "    stage_2_outputs = out['stage_2_outputs']\n",
    "    stage_2_titles = [e['title'] for e in stage_2_outputs]\n",
    "    stage_2_summaries = [e['summary'] for e in stage_2_outputs]\n",
    "    final_summary = out['final_summary']\n",
    "    \n",
    "    summarized_podcast = {\n",
    "        \"episode_number\": podcast['episode_number'],\n",
    "        \"title_and_summary_array\": stage_2_outputs,\n",
    "        \"final_summary\": final_summary\n",
    "    }\n",
    "    \n",
    "    with open(f\"./summarized_dataset/podcast_summaries_{podcast['episode_number']}.json\", \"w\") as outfile: \n",
    "        json.dump(summarized_podcast, outfile)\n",
    "\n",
    "#     break\n",
    "    \n",
    "# print(podcast_summary)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d228f8d1b134e326a52396b2016d42a4e7c84199cf5eb27412c1836171e03131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
