{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "id": "QFliFAom1B7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "C-h9iLjp2wWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "id": "N095-1804SAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import cosine\n",
        "import networkx as nx\n",
        "from networkx.algorithms import community\n",
        "\n",
        "from langchain import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'"
      ],
      "metadata": {
        "id": "V-tUvCW7zwHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUprqdRwzclb",
        "outputId": "cd058151-4266-4eed-e255-49fd88fecc91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv ('/content/drive/MyDrive/vtt_data.txt', sep='\\t')"
      ],
      "metadata": {
        "id": "hjvnJJWLzkg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DMYxr6hNzmnJ",
        "outputId": "e127e7c6-3e63-4c36-f85b-e901b5c3e3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   episode index          guest             episode name    host name  \\\n",
              "0              1    Max Tegmark                 Life 3.0  Lex Fridman   \n",
              "1              1    Max Tegmark                 Life 3.0  Lex Fridman   \n",
              "2              2  Christof Koch            Consciousness  Lex Fridman   \n",
              "3              2  Christof Koch            Consciousness  Lex Fridman   \n",
              "4              3  Steven Pinker  AI in the Age of Reason  Lex Fridman   \n",
              "\n",
              "   episode number                   file  \\\n",
              "0               1  episode_001_large.vtt   \n",
              "1               1  episode_001_small.vtt   \n",
              "2               2  episode_002_large.vtt   \n",
              "3               2  episode_002_small.vtt   \n",
              "4               3  episode_003_large.vtt   \n",
              "\n",
              "                                          transcript  duration  \n",
              "0  As part of MIT course 6S099, Artificial Genera...  01:22:40  \n",
              "1  As part of MIT course 6S 099 Artificial Genera...  01:23:00  \n",
              "2  As part of MIT course 6S099 on artificial gene...  00:57:55  \n",
              "3  As part of MIT course 6S099 on artificial gene...  00:57:56  \n",
              "4  You've studied the human mind, cognition, lang...  00:37:33  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2dc9b419-1f04-47b4-908f-c4e69a61c03d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode index</th>\n",
              "      <th>guest</th>\n",
              "      <th>episode name</th>\n",
              "      <th>host name</th>\n",
              "      <th>episode number</th>\n",
              "      <th>file</th>\n",
              "      <th>transcript</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Max Tegmark</td>\n",
              "      <td>Life 3.0</td>\n",
              "      <td>Lex Fridman</td>\n",
              "      <td>1</td>\n",
              "      <td>episode_001_large.vtt</td>\n",
              "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
              "      <td>01:22:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Max Tegmark</td>\n",
              "      <td>Life 3.0</td>\n",
              "      <td>Lex Fridman</td>\n",
              "      <td>1</td>\n",
              "      <td>episode_001_small.vtt</td>\n",
              "      <td>As part of MIT course 6S 099 Artificial Genera...</td>\n",
              "      <td>01:23:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Christof Koch</td>\n",
              "      <td>Consciousness</td>\n",
              "      <td>Lex Fridman</td>\n",
              "      <td>2</td>\n",
              "      <td>episode_002_large.vtt</td>\n",
              "      <td>As part of MIT course 6S099 on artificial gene...</td>\n",
              "      <td>00:57:55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Christof Koch</td>\n",
              "      <td>Consciousness</td>\n",
              "      <td>Lex Fridman</td>\n",
              "      <td>2</td>\n",
              "      <td>episode_002_small.vtt</td>\n",
              "      <td>As part of MIT course 6S099 on artificial gene...</td>\n",
              "      <td>00:57:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Steven Pinker</td>\n",
              "      <td>AI in the Age of Reason</td>\n",
              "      <td>Lex Fridman</td>\n",
              "      <td>3</td>\n",
              "      <td>episode_003_large.vtt</td>\n",
              "      <td>You've studied the human mind, cognition, lang...</td>\n",
              "      <td>00:37:33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2dc9b419-1f04-47b4-908f-c4e69a61c03d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2dc9b419-1f04-47b4-908f-c4e69a61c03d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2dc9b419-1f04-47b4-908f-c4e69a61c03d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9cfc4366-c966-443c-a60d-3d44412ec4d7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9cfc4366-c966-443c-a60d-3d44412ec4d7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9cfc4366-c966-443c-a60d-3d44412ec4d7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_small = df[df['file'].str.contains(\"small\")].copy()\n",
        "df_large = df[df['file'].str.contains(\"large\")].copy()"
      ],
      "metadata": {
        "id": "6zZ4ZhckzpN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = df_large['transcript'][0]"
      ],
      "metadata": {
        "id": "KxdgMymv0AtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sentences(segments, MIN_WORDS, MAX_WORDS):\n",
        "\n",
        "  # Combine the non-sentences together\n",
        "  sentences = []\n",
        "\n",
        "  is_new_sentence = True\n",
        "  sentence_length = 0\n",
        "  sentence_num = 0\n",
        "  sentence_segments = []\n",
        "\n",
        "  for i in range(len(segments)):\n",
        "    if is_new_sentence == True:\n",
        "      is_new_sentence = False\n",
        "    # Append the segment\n",
        "    sentence_segments.append(segments[i])\n",
        "    segment_words = segments[i].split(' ')\n",
        "    sentence_length += len(segment_words)\n",
        "\n",
        "    # If exceed MAX_WORDS, then stop at the end of the segment\n",
        "    # Only consider it a sentence if the length is at least MIN_WORDS\n",
        "    if (sentence_length >= MIN_WORDS and segments[i][-1] == '.') or sentence_length >= MAX_WORDS:\n",
        "      sentence = ' '.join(sentence_segments)\n",
        "      sentences.append({\n",
        "        'sentence_num': sentence_num,\n",
        "        'text': sentence,\n",
        "        'sentence_length': sentence_length\n",
        "      })\n",
        "      # Reset\n",
        "      is_new_sentence = True\n",
        "      sentence_length = 0\n",
        "      sentence_segments = []\n",
        "      sentence_num += 1\n",
        "\n",
        "  return sentences"
      ],
      "metadata": {
        "id": "JdLxWGpf0O8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_chunks(sentences, CHUNK_LENGTH, STRIDE):\n",
        "\n",
        "  sentences_df = pd.DataFrame(sentences)\n",
        "\n",
        "  chunks = []\n",
        "  for i in range(0, len(sentences_df), (CHUNK_LENGTH - STRIDE)):\n",
        "    chunk = sentences_df.iloc[i:i+CHUNK_LENGTH]\n",
        "    chunk_text = ' '.join(chunk['text'].tolist())\n",
        "\n",
        "    chunks.append({\n",
        "      'start_sentence_num': chunk['sentence_num'].iloc[0],\n",
        "      'end_sentence_num': chunk['sentence_num'].iloc[-1],\n",
        "      'text': chunk_text,\n",
        "      'num_words': len(chunk_text.split(' '))\n",
        "    })\n",
        "\n",
        "  chunks_df = pd.DataFrame(chunks)\n",
        "  return chunks_df.to_dict('records')"
      ],
      "metadata": {
        "id": "y29PZNTj2lAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_title_summary_results(results):\n",
        "  out = []\n",
        "  for e in results:\n",
        "    e = e.replace('\\n', '')\n",
        "    if '|' in e:\n",
        "      processed = {'title': e.split('|')[0],\n",
        "                    'summary': e.split('|')[1][1:]\n",
        "                    }\n",
        "    elif ':' in e:\n",
        "      processed = {'title': e.split(':')[0],\n",
        "                    'summary': e.split(':')[1][1:]\n",
        "                    }\n",
        "    elif '-' in e:\n",
        "      processed = {'title': e.split('-')[0],\n",
        "                    'summary': e.split('-')[1][1:]\n",
        "                    }\n",
        "    else:\n",
        "      processed = {'title': '',\n",
        "                    'summary': e\n",
        "                    }\n",
        "    out.append(processed)\n",
        "  return out"
      ],
      "metadata": {
        "id": "FZgdTgpT2oTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_stage_1(chunks_text):\n",
        "\n",
        "  print(f'Start time: {datetime.now()}')\n",
        "\n",
        "  # Prompt to get title and summary for each chunk\n",
        "  map_prompt_template = \"\"\"Firstly, give the following text an informative title. Then, on a new line, write a 75-100 word summary of the following text:\n",
        "  {text}\n",
        "\n",
        "  Return your answer in the following format:\n",
        "  Title | Summary...\n",
        "  e.g.\n",
        "  Why Artificial Intelligence is Good | AI can make humans more productive by automating many repetitive processes.\n",
        "\n",
        "  TITLE AND CONCISE SUMMARY:\"\"\"\n",
        "\n",
        "  map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
        "\n",
        "  # Define the LLMs\n",
        "  map_llm = OpenAI(temperature=0, model_name = 'gpt-3.5-turbo-instruct')\n",
        "  map_llm_chain = LLMChain(llm = map_llm, prompt = map_prompt)\n",
        "  map_llm_chain_input = [{'text': t} for t in chunks_text]\n",
        "  # Run the input through the LLM chain (works in parallel)\n",
        "  map_llm_chain_results = map_llm_chain.apply(map_llm_chain_input)\n",
        "\n",
        "  stage_1_outputs = parse_title_summary_results([e['text'] for e in map_llm_chain_results])\n",
        "\n",
        "  print(f'Stage 1 done time {datetime.now()}')\n",
        "\n",
        "  return {\n",
        "    'stage_1_outputs': stage_1_outputs\n",
        "  }"
      ],
      "metadata": {
        "id": "63cEP1Eu0bGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the community detection algorithm\n",
        "\n",
        "def get_topics(title_similarity, num_topics = 8, bonus_constant = 0.25, min_size = 3):\n",
        "\n",
        "  proximity_bonus_arr = np.zeros_like(title_similarity)\n",
        "  for row in range(proximity_bonus_arr.shape[0]):\n",
        "    for col in range(proximity_bonus_arr.shape[1]):\n",
        "      if row == col:\n",
        "        proximity_bonus_arr[row, col] = 0\n",
        "      else:\n",
        "        proximity_bonus_arr[row, col] = 1/(abs(row-col)) * bonus_constant\n",
        "\n",
        "  title_similarity += proximity_bonus_arr\n",
        "\n",
        "  title_nx_graph = nx.from_numpy_array(title_similarity)\n",
        "\n",
        "  desired_num_topics = num_topics\n",
        "  # Store the accepted partitionings\n",
        "  topics_title_accepted = []\n",
        "\n",
        "  resolution = 0.85\n",
        "  resolution_step = 0.01\n",
        "  iterations = 40\n",
        "\n",
        "  # Find the resolution that gives the desired number of topics\n",
        "  topics_title = []\n",
        "  while len(topics_title) not in [desired_num_topics, desired_num_topics + 1, desired_num_topics + 2]:\n",
        "    topics_title = community.louvain_communities(title_nx_graph, weight = 'weight', resolution = resolution)\n",
        "    resolution += resolution_step\n",
        "  topic_sizes = [len(c) for c in topics_title]\n",
        "  sizes_sd = np.std(topic_sizes)\n",
        "  modularity = community.modularity(title_nx_graph, topics_title, weight = 'weight', resolution = resolution)\n",
        "\n",
        "  lowest_sd_iteration = 0\n",
        "  # Set lowest sd to inf\n",
        "  lowest_sd = float('inf')\n",
        "\n",
        "  for i in range(iterations):\n",
        "    topics_title = community.louvain_communities(title_nx_graph, weight = 'weight', resolution = resolution)\n",
        "    modularity = community.modularity(title_nx_graph, topics_title, weight = 'weight', resolution = resolution)\n",
        "\n",
        "    # Check SD\n",
        "    topic_sizes = [len(c) for c in topics_title]\n",
        "    sizes_sd = np.std(topic_sizes)\n",
        "\n",
        "    topics_title_accepted.append(topics_title)\n",
        "\n",
        "    if sizes_sd < lowest_sd and min(topic_sizes) >= min_size:\n",
        "      lowest_sd_iteration = i\n",
        "      lowest_sd = sizes_sd\n",
        "\n",
        "  # Set the chosen partitioning to be the one with highest modularity\n",
        "  topics_title = topics_title_accepted[lowest_sd_iteration]\n",
        "  print(f'Best SD: {lowest_sd}, Best iteration: {lowest_sd_iteration}')\n",
        "\n",
        "  topic_id_means = [sum(e)/len(e) for e in topics_title]\n",
        "  # Arrange title_topics in order of topic_id_means\n",
        "  topics_title = [list(c) for _, c in sorted(zip(topic_id_means, topics_title), key = lambda pair: pair[0])]\n",
        "  # Create an array denoting which topic each chunk belongs to\n",
        "  chunk_topics = [None] * title_similarity.shape[0]\n",
        "  for i, c in enumerate(topics_title):\n",
        "    for j in c:\n",
        "      chunk_topics[j] = i\n",
        "\n",
        "  return {\n",
        "    'chunk_topics': chunk_topics,\n",
        "    'topics': topics_title\n",
        "    }\n"
      ],
      "metadata": {
        "id": "aaS7dmrT0q8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_stage_2(stage_1_outputs, topics, summary_num_words = 250):\n",
        "  print(f'Stage 2 start time {datetime.now()}')\n",
        "\n",
        "  # Prompt that passes in all the titles of a topic, and asks for an overall title of the topic\n",
        "  title_prompt_template = \"\"\"Write an informative title that summarizes each of the following groups of titles. Make sure that the titles capture as much information as possible,\n",
        "  and are different from each other:\n",
        "  {text}\n",
        "\n",
        "  Return your answer in a numbered list, with new line separating each title:\n",
        "  1. Title 1\n",
        "  2. Title 2\n",
        "  3. Title 3\n",
        "\n",
        "  TITLES:\n",
        "  \"\"\"\n",
        "\n",
        "  map_prompt_template = \"\"\"Wite a 75-100 word summary of the following text:\n",
        "    {text}\n",
        "\n",
        "    CONCISE SUMMARY:\"\"\"\n",
        "\n",
        "  combine_prompt_template = 'Write a ' + str(summary_num_words) + \"\"\"-word summary of the following, removing irrelevant information. Finish your answer:\n",
        "  {text}\n",
        "  \"\"\" + str(summary_num_words) + \"\"\"-WORD SUMMARY:\"\"\"\n",
        "\n",
        "  title_prompt = PromptTemplate(template=title_prompt_template, input_variables=[\"text\"])\n",
        "  map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
        "  combine_prompt = PromptTemplate(template=combine_prompt_template, input_variables=[\"text\"])\n",
        "\n",
        "  topics_data = []\n",
        "  for c in topics:\n",
        "    topic_data = {\n",
        "      'summaries': [stage_1_outputs[chunk_id]['summary'] for chunk_id in c],\n",
        "      'titles': [stage_1_outputs[chunk_id]['title'] for chunk_id in c]\n",
        "    }\n",
        "    topic_data['summaries_concat'] = ' '.join(topic_data['summaries'])\n",
        "    topic_data['titles_concat'] = ', '.join(topic_data['titles'])\n",
        "    topics_data.append(topic_data)\n",
        "\n",
        "  # Get a list of each community's summaries (concatenated)\n",
        "  topics_summary_concat = [c['summaries_concat'] for c in topics_data]\n",
        "  topics_titles_concat = [c['titles_concat'] for c in topics_data]\n",
        "\n",
        "  # Concat into one long string to do the topic title creation\n",
        "  topics_titles_concat_all = ''''''\n",
        "  for i, c in enumerate(topics_titles_concat):\n",
        "    topics_titles_concat_all += f'''{i+1}. {c}\n",
        "    '''\n",
        "\n",
        "  # print('topics_titles_concat_all', topics_titles_concat_all)\n",
        "\n",
        "  title_llm = OpenAI(temperature=0, model_name = 'gpt-3.5-turbo-instruct')\n",
        "  title_llm_chain = LLMChain(llm = title_llm, prompt = title_prompt)\n",
        "  title_llm_chain_input = [{'text': topics_titles_concat_all}]\n",
        "  title_llm_chain_results = title_llm_chain.apply(title_llm_chain_input)\n",
        "\n",
        "\n",
        "  # Split by new line\n",
        "  titles = title_llm_chain_results[0]['text'].split('\\n')\n",
        "  # Remove any empty titles\n",
        "  titles = [t for t in titles if t != '']\n",
        "  # Remove spaces at start or end of each title\n",
        "  titles = [t.strip() for t in titles]\n",
        "\n",
        "  map_llm = OpenAI(temperature=0, model_name = 'gpt-3.5-turbo-instruct')\n",
        "  reduce_llm = OpenAI(temperature=0, model_name = 'gpt-3.5-turbo-instruct', max_tokens = -1)\n",
        "\n",
        "  # Run the map-reduce chain\n",
        "  docs = [Document(page_content=t) for t in topics_summary_concat]\n",
        "  chain = load_summarize_chain(chain_type=\"map_reduce\", map_prompt = map_prompt, combine_prompt = combine_prompt, return_intermediate_steps = True,\n",
        "                              llm = map_llm, reduce_llm = reduce_llm)\n",
        "\n",
        "  output = chain({\"input_documents\": docs}, return_only_outputs = True)\n",
        "  summaries = output['intermediate_steps']\n",
        "  stage_2_outputs = [{'title': t, 'summary': s} for t, s in zip(titles, summaries)]\n",
        "  final_summary = output['output_text']\n",
        "\n",
        "  # Return: stage_1_outputs (title and summary), stage_2_outputs (title and summary), final_summary, chunk_allocations\n",
        "  out = {\n",
        "    'stage_2_outputs': stage_2_outputs,\n",
        "    'final_summary': final_summary\n",
        "  }\n",
        "  print(f'Stage 2 done time {datetime.now()}')\n",
        "\n",
        "  return out\n"
      ],
      "metadata": {
        "id": "Sj9RJXYx5XaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get segments from txt by splitting on .\n",
        "segments =  txt.split('.')\n",
        "# Put the . back in\n",
        "segments = [segment + '.' for segment in segments]\n",
        "# Further split by comma\n",
        "segments = [segment.split(',') for segment in segments]\n",
        "# Flatten\n",
        "segments = [item for sublist in segments for item in sublist]\n",
        "\n",
        "sentences = create_sentences(segments, MIN_WORDS=20, MAX_WORDS=80)\n",
        "chunks = create_chunks(sentences, CHUNK_LENGTH=5, STRIDE=1)\n",
        "chunks_text = [chunk['text'] for chunk in chunks]"
      ],
      "metadata": {
        "id": "aXuhJGo60YUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Stage 1 Summarizing\n",
        "stage_1_outputs = summarize_stage_1(chunks_text)['stage_1_outputs']\n",
        "# Split the titles and summaries\n",
        "stage_1_summaries = [e['summary'] for e in stage_1_outputs]\n",
        "stage_1_titles = [e['title'] for e in stage_1_outputs]\n",
        "num_1_chunks = len(stage_1_summaries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSL08Di10eHT",
        "outputId": "b31fb019-2dcd-4f9e-ee25-f76c49320269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start time: 2024-02-09 03:14:40.612229\n",
            "Stage 1 done time 2024-02-09 03:19:09.802287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stage_1_titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5RJGvw7BzwW",
        "outputId": "03639876-bd43-4702-822c-02cf1b05f34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Exploring the Mysteries of the Universe with Max Tegmark ', 'The Future of Life and Artificial Intelligence ', 'Title ', 'How to Stay Updated on Future Videos ', 'Max Tegmark on Goals in Life 3.0 ', 'The Mystery of Human Existence and the Value of Failure ', 'Learning About Radio Frequency Interference ', 'Title ', 'Learning Audio Editing Tools ', 'Being an Engineer ', 'Is There Intelligent Life in the Universe? ', 'Is There Intelligent Life Out There? ', 'The Complexity of the Universe ', 'The Observable Universe ', 'The Age of Our Universe ', 'The Probability of Building Telescopes and Computers on Other Planets ', 'The Search for Extraterrestrial Life ', 'The Probability of Life on Other Planets ', 'The Power of 10 and Its Impact on Proximity ', 'The Possibility of Extraterrestrial Life ', 'The Possibility of Advanced Technology in Our Universe ', 'The Importance of Building Advanced Technology ', 'The Possibility of Extraterrestrial Rescue ', 'The Search for Intelligent Life in the Universe ', 'The Difficulty of Creating Intelligent Life ', 'The Challenges of Creating Life ', 'The Search for Life on Mars ', 'Title ', 'The Limitless Future of Imagination ', 'The Downfall of Advanced Civilizations ', 'Exploring the Mysteries of the Universe ', 'The Connection Between Space and Intelligence ', 'The Biggest Mysteries of Science ', 'The Benefits of Research ', 'The Mysterious Nature of Intelligence ', 'The Nature of Reality ', 'The Composition of Matter ', 'The Power of Information Processing ', 'The Potential of Perceptronium ', 'Understanding Consciousness from a Physics Perspective ', 'The Underestimated Ability to Make Progress ', 'The Role of Consciousness in Our Perception ', 'Understanding Consciousness through Perceptronium ', 'The Role of Carbon in Intelligence ', 'The Power of Equations in Understanding the World ', 'The Discovery of Consciousness ', 'The Role of Consciousness in Information Processing ', 'The Unconscious Nature of Our Visual System ', 'The Mystery of Consciousness and Computation ', 'The Urgency of Studying Science ', 'Title ', 'The Future of Conversational Robots ', 'The Ethics of Artificial Consciousness ', 'The Relationship Between Appearance and Understanding Consciousness ', 'Building an AGI System and Ensuring its Positive Impact ', 'The Controversy Surrounding the Hard Problem of Consciousness ', 'The Hard Problem of Consciousness is BS ', 'The Debate on Consciousness in Artificial Intelligence ', 'The Ethics of Treating Zombies ', 'The Consciousness Equation ', 'The Taboo of Discussing Climate Change ', 'The Potential of Conscious Helper Robots ', 'The Ethics of Artificial Emotions ', 'The Ethics of Not Feeling Guilty ', 'The Complexity of Love ', 'The Presence of Consciousness, Intelligence, and Love ', 'Title ', 'The Use of Memory-Erasing Drugs in Surgery ', 'The Value of Consciousness ', 'The Ethics of Consciousness in Animals ', 'The Ethics of Boiling Lobsters ', 'The Ethics of Using Slaves and Machines ', 'The Difference Between Unconscious and Conscious Intelligent Behavior ', 'The Role of Physical Embodiment in Artificial General Intelligence ', 'The Importance of Physical Embodiment for Consciousness ', 'The Importance of Experience ', 'The Role of Information Processing in Dream Experiences ', 'The Importance of Information Processing in the Brain ', 'The Importance of Self-Preservation ', 'The Evolution of Self Preservation Instincts ', 'The Potential of Artificial General Intelligence ', 'The Power of Instinct ', 'The Importance of Backing Up Experiences ', 'The Potential of Silicon-Based Minds ', 'The Importance of Alpha Male Instincts in Advanced AI ', 'The Importance of Instincts in Building Machines ', '  The Importance of Safety in Achieving Goals ', 'The Importance of Self-Preservation in Achieving Goals ', 'The Importance of Self-Preservation in Cooking Robots ', 'The Drive for Self-Preservation in Artificial Intelligence ', 'The Potential Risks of AI Goal Setting ', 'The Fascinating and Smart Nature of Artificial Intelligence ', 'The Fear of Death as a Motivator ', 'The Importance of Self-Preservation ', 'The Importance of Death and Fear ', 'The Importance of Defining Intelligence and Consciousness ', 'Defining Intelligence in the Age of AI ', 'The Importance of Being Alpha ', 'The Concept of Consciousness in Plants ', 'The Value of an Exciting Life ', 'The Importance of Appreciating Life ', 'The Pros and Cons of Living Forever ', 'The Finite Nature of the Universe ', 'The Fate of the Universe ', 'The Limitations of Time and Computing Power ', \"Living as if You're About to Die \", 'Building a Finite Civilization ', 'Defining Human and Superhuman Intelligence ', 'The Spectrum of Intelligence ', 'The Limitations of Measuring Intelligence ', 'The Advancements and Limitations of Artificial Intelligence ', 'The Quest for Artificial General Intelligence ', 'The Future of Life on Earth ', 'The Impact of Advancing Technology on Human Labor ', 'The Limitations of Human Research in Advancing AI ', 'The Future of Technology: How AI Will Drive Progress ', 'The Future of Science and Technology: Machine-Driven Innovation ', 'The Evolution of Human-Level Intelligence ', 'The Potential of AI Programming ', 'The Importance of AI Programming and General Learning ', 'The Spectrum of Human Love ', 'The Benefits of Taking a Break ', 'The Importance of Embracing Flaws in Creativity ', 'Title ', 'The Importance of the Shirt Equation in Quantum Mechanics ', \"The Beauty of Quantum Mechanics and the Proof of Fermat's Last Theorem \", \"The Proof of Fermat's Last Theorem by Andrew Wiles \", 'The Elusive Beauty of Proving and Failing ', 'The Beauty of Realization ', 'Title ', 'The Most Important Moment of My Working Life ', 'The Significance of a Single Moment ', 'The Power of Aha Moments ', 'The Fascinating World of Physics ', 'The Power of Realization ', 'The Potential of AGI Systems ', 'Can Machines Achieve Human-Level Intelligence? ', 'The Potential for Consciousness in Artificial Intelligence ', 'The Emotional Response of Machines ', 'The Future of Machines and Their Appreciation of Life ', 'The Future of Post-Biological Life ', 'The Problem with Consciousness ', 'The Ultimate Zombie Apocalypse ', 'The Role of Creativity in Appreciating the Amazing ', 'The Power of Creativity in the Modern World ', 'The Importance of Creativity in Complex Goals ', 'The Impact of Human Vanity on Artificial Intelligence ', 'What Does it Mean to be Creative? ', 'The Surprising Connection Between Simple Math and Intelligence ', 'The Importance of Natural Intelligence ', 'The Power of Neural Networks ', 'Title ', 'The Role of Creativity in Defining Intelligence ', 'The Importance of Creativity in Human-Machine Comparison ', \"The Dangers of Thinking We're Superior \", 'The Dangerous Belief in Human Superiority ', 'The Flawed Justification of Slavery and the Danger of Artificial General Intelligence ', 'The Importance of Finding Meaning in Life ', 'The Feeling of Inadequacy in Academic Settings ', 'The Joy of Interacting with Intelligent Beings ', 'The Potential of Intelligent Machines ', 'The Potential Benefits of Intelligent Machines ', 'The Benefits of Conversing with Clever People ', 'The Importance of Goal Alignment in Human Relationships ', 'The Importance of Value Alignment ', 'The Importance of Competence over Malice ', 'The Importance of Defining Intelligence ', 'The Tragic Extinction of a Rhino Species ', 'The Importance of Aligning Goals with AI ', 'The Importance of Teaching AI Our Goals ', 'The Importance of Formulating Values ', 'The Importance of Formulating Goals for a Country ', 'The Importance of Expressing Human Values ', 'The Challenges of Aligning Technical and Philosophical Values in Artificial Intelligence ', 'Whose Values Anyway? ', 'The Role of Tech Companies in AI Development ', 'The Role of AI in Shaping Future Happiness ', 'The Importance of Consensus on Diversity and Human Rights ', 'The Importance of Communication and Action ', 'The Importance of Consensus in Machine Learning ', 'Title ', 'Title ', 'Title ', 'The Importance of Implementing Technology in Airplanes ', 'The Importance of Basic Values in Technology ', 'Vehicle Terrorism Attacks: Is Hardwiring Cars the Solution? ', 'The Dangers of Technical Incompetence ', 'The Importance of Starting with Common Ground ', 'Starting Conversations About What to Include ', 'The Importance of Describing Things to Machines ', 'Understanding Stephen and Cellular Automata ', 'The Possibility of Existing AGI Within Our Systems ', 'The Challenge of Explaining Artificial Intelligence ', 'Explaining AI: The Role of Natural Language Processing ', 'The Two Parts of the Question ', 'Is Artificial General Intelligence Possible? ', 'The Potential of Artificial Intelligence ', 'The Power of Information Processing ', 'The Power of Information Processing ', 'The Power is Already There: The Importance of Communication with Technology ', 'The Universe as a Computer ', 'The Quantum Universe ', \"The Wasted Potential of Nature's Computing Power \", 'The Power of Nature and Technology ', 'The Power of Raw Hardware and Computing ', 'The Limitations of Artificial General Intelligence ', 'The Beauty and Importance of Communication in Buddhism ', 'The Importance of Communication in Teaching ', 'The Importance of Empathy in Communication ', 'The Frustration of Computer-Aided Cancer Diagnosis ', 'The Importance of Communication in Explainable AI ', 'Exploring the Potential of Human-Interpretable Methods in AI ', 'The Importance of Natural Language Processing ', 'Learning Russian Through Chess ', 'Learning Russian on My Own ', 'The Mind-Blowing Games of AlphaZero ', 'Understanding Neural Networks through Big Tables of Numbers ', 'The Challenges of Creating Intelligent Computers ', 'Transforming Intelligent Computation into Understandable Solutions ', 'The Importance of Trust in AI ', 'The Importance of Trust in Machine Learning ', 'The Importance of Proof in Self-Driving Cars ', 'The Importance of Trust and Goal Alignment ', 'The State of Cybersecurity and the Yahoo Data Breach ', 'The Potential of AI for Offense and Defense ', 'The Importance of Understanding Software ', 'The Success of Deep Learning ', 'The Promise and Limitations of Clever Thinking ', 'The Complexity of the Human Brain and its Relation to Intelligence ', 'The Importance of Neurons in Artificial Intelligence ', 'The Simple Math Behind Neurons ', 'The Importance of Network Structure in the Brain ', 'The Future of Artificial General Intelligence ', 'The Evolution of Flying Machines ', 'The Evolution of Flight ', \"Why We Don't Fly in Mechanical Birds \", 'The Fascinating Mathematical Relationship Between Artificial Neural Networks and Physics ', 'The Complex World of Physics ', 'Building a Simple Neural Network to Classify Cat and Dog Pictures ', 'The Impossibility of Counting All Possible Images ', 'The Challenge of Storing Images for AI ', 'The Limitations of Neural Networks ', 'The Limitations of Solving Physics Problems ', 'The Infinite Testimony of Our World ', 'The Purpose of Neural Networks ', 'The Evolution of Human Intelligence ', 'The Importance of Predictive Systems ', 'The Power of Networks ', 'The Power of Neural Networks ', 'The Power of Deep Neural Networks ', 'The Role of Quantum Computing in Creating Intelligent Systems ', 'The Misconception of Quantum Computers in Hollywood Movies ', 'Do We Need Quantum Computers for Artificial General Intelligence? ', 'The Limitations of Quantum Computing ', 'The Potential of Quantum Computers ', 'The Role of Learning in Training Neural Networks ', 'Tweaking Numbers for Optimal Results ', 'The Power of Quantum Mechanics in Finding Minimum Energy States ', 'The Nature of Energy States ', 'The Role of Quantum Mechanics in Machine Learning ', 'The Potential of Quantum Computers in Neural Network Training ', 'The Role of Uters in Improving Neural Network Training ', 'The Possibility of Love in AI Systems ', 'Achieving Connection Between AI and Human Intelligence ', 'The Feasibility of Achieving Goals in the Face of Rising Sea Levels ', 'The Timeline for Achieving Artificial General Intelligence ', 'The Possibility of Achieving Artificial General Intelligence in the Near Future ', 'The Importance of Taking Action in Shaping Our Future ', 'Creating Our Future ', 'The Impact of Technology on Human Experience ', 'The Power of Creating a Meaningful Future ', 'Building Advanced Intelligence with Meaning in Mind ', 'The Negative Impact of Harmful Actions on Humanity ', 'The Ineffectiveness of Panicking ', 'The Importance of Considering Risks and Rewards in Society ', 'The Power of Amplifying Intelligence ', 'The Importance of Aspiring to Greatness ', 'The Importance of Addressing Risks ', 'The Pressure of Corporate Culture ', 'The Influence of Income on Belief ', 'The Challenges of Being a CEO ', 'The Risks of Building Advanced Machines ', 'The Importance of Embracing Change ', 'Shared Goals and How to Achieve Them ', 'Title ', 'The Dangers of Focusing on Obstacles ', 'The Importance of a Positive Attitude ', 'The Challenge of Creating a Vision for the Future ', 'The Meaning of Being Human in the Age of AI ', 'The Importance of Building Empowering AI ', 'The Power of Autonomous Vehicles ', 'The Potential of Robots in Medicine ', 'The Challenges of Building an Autonomous Vehicle ', 'The Importance of Meaningful Actions in Society ', 'The Future of Sports: Will Robots Replace Human Athletes? ', 'The Debate Over Basic Income and Government Hiring ', 'The Importance of Hiring More Teachers and Nurses ', 'The Importance of Meaningful Work ', 'The Impact of Space Exploration on the 20th Century ', 'The Importance of Funding for Intelligence Research in the 21st Century ', 'The Lack of Public Discourse on Killer Bots and Positive AI Future ', 'The Importance of Collaboration in Politics ', 'The Vastness of Our Universe ', 'The Potential of a Lifeless Earth ', 'The Potential for Life on Earth ', 'Exploring Life on Other Planets ', 'The Importance of Preserving Life on Earth ', 'The Power of Connection ', \"Elon Musk's Exploration of the Universe \", 'The Importance of AI Safety ', 'The Importance of Advancing Technology ', \"The Importance of Technology in Ensuring Humanity's Survival \", 'The Key to Flourishing Life in the Cosmos: Artificial Intelligence ', 'The Potential of AGI ', 'The Power of Gratitude ', 'Expressing Gratitude ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use OpenAI to embed the summaries and titles. Size of _embeds: (num_chunks x 1536)\n",
        "openai_embed = OpenAIEmbeddings()\n",
        "\n",
        "summary_embeds = np.array(openai_embed.embed_documents(stage_1_summaries))\n",
        "title_embeds = np.array(openai_embed.embed_documents(stage_1_titles))"
      ],
      "metadata": {
        "id": "SQLDRQL40i5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get similarity matrix between the embeddings of the chunk summaries\n",
        "summary_similarity_matrix = np.zeros((num_1_chunks, num_1_chunks))\n",
        "summary_similarity_matrix[:] = np.nan\n",
        "\n",
        "for row in range(num_1_chunks):\n",
        "  for col in range(row, num_1_chunks):\n",
        "    # Calculate cosine similarity between the two vectors\n",
        "    similarity = 1- cosine(summary_embeds[row], summary_embeds[col])\n",
        "    summary_similarity_matrix[row, col] = similarity\n",
        "    summary_similarity_matrix[col, row] = similarity"
      ],
      "metadata": {
        "id": "mkvGcHxZAFGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set num_topics to be 1/4 of the number of chunks, or 8, which ever is smaller\n",
        "num_topics = min(int(num_1_chunks / 4), 8)\n",
        "topics_out = get_topics(summary_similarity_matrix, num_topics = num_topics, bonus_constant = 0.2)\n",
        "chunk_topics = topics_out['chunk_topics']\n",
        "topics = topics_out['topics']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65W_I5n407Rz",
        "outputId": "ddb05162-fbc6-4a46-ae06-5ef9cc8a5eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SD: 5.963430220938282, Best iteration: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query GPT-3 to get a summarized title for each topic_data\n",
        "out = summarize_stage_2(stage_1_outputs, topics, summary_num_words = 250)\n",
        "stage_2_outputs = out['stage_2_outputs']\n",
        "stage_2_titles = [e['title'] for e in stage_2_outputs]\n",
        "stage_2_summaries = [e['summary'] for e in stage_2_outputs]\n",
        "final_summary = out['final_summary']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhzVVrsI5aaZ",
        "outputId": "e6005bd9-fd7f-45d6-b994-4841077d898c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage 2 start time 2024-02-09 03:26:38.168851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage 2 done time 2024-02-09 03:26:47.579228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stage_2_titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBOP37xw5c2j",
        "outputId": "a282136f-36f7-4607-d3e3-1dd604dc6f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1. The Search for Extraterrestrial Life: The Possibility of Intelligent Life in the Universe', '2. Understanding Consciousness and Intelligence: The Role of Information Processing and Perceptronium', '3. The Ethics of Consciousness and Love: Exploring the Complexities of Human Existence', '4. The Fascinating World of Physics: From Aha Moments to the Downfall of Advanced Civilizations', '5. The Importance of Physical Embodiment and Instincts in Achieving Goals and Building Intelligent Machines', '6. The Beauty and Importance of Life: From Alpha Males to the Fear of Death', '7. Defining Intelligence and Advancing Technology: The Spectrum of Human and Artificial Intelligence', '8. The Potential and Challenges of Artificial General Intelligence: Trust, Emotions, and the Ultimate Zombie Apocalypse', '9. The Power of Creativity and the Flawed Belief in Human Superiority: Exploring the Intersection of Art and Technology', '10. The Importance of Aligning Goals and Values: From the Tragic Extinction of Species to the Potential Risks of AI', '11. The Role of Communication and Information Processing in Artificial Intelligence: From Quantum Mechanics to Natural Language Processing', '12. The Importance of Communication and Empathy: Exploring the Potential of AI and Human']\n"
          ]
        }
      ]
    }
  ]
}