{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from langchain import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "episodes = [22,23,79,94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt_template = \"\"\"You are evaluating the summary text to determine if it is organized or not.\n",
    "\n",
    "Here is the data:\n",
    "[BEGIN DATA]\n",
    "************\n",
    "[Summary]: {summary}\n",
    "[END DATA]\n",
    "\n",
    "Your response must be either Very, Somewhat, or Not. Your response should not contain any text\n",
    "or characters aside from that.\n",
    "\n",
    "The string Very means that summary is very organized.\n",
    "\n",
    "The string Somewhat means that summary is somewhat organized.\n",
    "\n",
    "The string Not means that summary is not organized.\n",
    "\n",
    "You response should also contain reasons behind your evaluation.\n",
    "\n",
    "Return your answer in the following format:\n",
    "  Very/Somewhat/Not | reasons...\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Summary\n",
      " This podcast explores the history and impact of TensorFlow 2.0, from its origins in Google Brain to its current status as an open-source ecosystem. The discussion covers key milestones like the birth of deep learning at Google, the rise of TensorFlow and Torch libraries, and the integration with Google Cloud. It delves into how TensorFlow has evolved to support various platforms and hardware, shaping AI advancements across industries.\n",
      "\n",
      "The podcast also discusses customized machine learning solutions such as Theano and Caffe, the growth of deep learning technology, and the importance of comprehensive documentation for making deep learning accessible to developers. It highlights transformer models, reinforcement learning, and generative adversarial networks pushing AI innovation's boundaries and their practicality in hobbyists and enterprises.\n",
      "\n",
      "The development of Keras 2.0 and its goal of simplifying API integration and usage is also explored. The growth of the TensorFlow ecosystem from Andrej Karpathy's ComNetJS to TensorFlow.js for both backend and frontend development, TensorFlow Extended for enhanced data pipelines, and TensorFlow Lite for mobile applications is discussed.\n",
      "\n",
      "The podcast delves into the two primary directions for advancing machine learning research and application using TensorFlow: pushing the boundaries of innovation and making advancements accessible to individuals outside academia. It also discusses the expanding ecosystem of machine learning across devices, challenges in TensorFlow.js integration, scaling TensorFlow while maintaining compatibility, and embracing change for designing with a clean slate.\n",
      "\n",
      "The podcast explores the evolution of TensorFlow and PyTorch, discussing their impact on graph processing and machine learning development, the benefits of competition and the iterative process that led to advancements like eager execution in TensorFlow 2.0. It also looks forward to future innovations in distributed computing and GPU operations.\n",
      "\n",
      "Lastly, the podcast discusses Google's journey from a bottom-up organization, the importance of team health, alignment, and individual superstars in AI projects like TensorFlow, and insights on achieving a balance between engineering excellence and team fit across various projects and teams at Google.\n",
      "## End of Summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bizon/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clearness evaluation score for episode 22\n",
      "[{'text': \"Very | The summary provides a comprehensive overview of the history and impact of TensorFlow 2.0, covering key milestones, customized machine learning solutions, the growth of the TensorFlow ecosystem, and the future of TensorFlow and PyTorch. It also discusses Google's journey and insights on achieving a balance between engineering excellence and team fit. The summary is clear and provides a detailed understanding of the topic.\"}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n",
      "\n",
      "## Summary\n",
      " This podcast explores the evolution of AI-generated poetry and emotional expression in technology, focusing on crafting conversational AI personalities and their potential to revolutionize digital art. It delves into how artificial intelligence is transforming the creative process through realistic simulations, automating repetitive tasks, and making art more accessible for expression and novelty. The podcast also discusses the integration of AI in design, raising questions about the role of human artists and designers as they evolve to become art directors or conceptual artists with computers as their creative partners.\n",
      "## End of Summary\n",
      "\n",
      "Clearness evaluation score for episode 23\n",
      "[{'text': 'Very | The summary clearly explains the focus of the podcast, which is the evolution of AI-generated poetry and emotional expression in technology. It also provides details about the impact of AI on the creative process and raises thought-provoking questions about the role of human artists in the future.'}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n",
      "\n",
      "## Summary\n",
      " In this podcast episode, renowned theoretical physicist Lee Smolin shares his critiques on physics and string theory while exploring beyond the quantum. The discussion delves into the connection between artificial intelligence and theoretical physics, emphasizing the importance of understanding first principles. The history of money is also explored, highlighting the significance of historical context in today's world. The podcast discusses the subjective nature of reality perception, arguing that the scientific method is not universally applicable and that reality is constantly changing. It delves into the importance of ethics and rigorous training in shaping a scientist's mindset while emphasizing repeatability and experimentation for validating theories within the scientific community. The podcast also investigates the impact of self-confidence on scientific innovation, using examples from physicists like Einstein, Newton, and Galileo.\n",
      "## End of Summary\n",
      "\n",
      "Clearness evaluation score for episode 79\n",
      "[{'text': 'Somewhat | The summary provides a lot of information about the podcast episode, but it jumps between different topics without a clear structure. It could benefit from organizing the information in a more coherent manner.'}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n",
      "\n",
      "## Summary\n",
      " In this podcast episode, Ilya Sutskever, co-founder and Chief Scientist at OpenAI, shares insights on deep learning, intelligence, and life as a highly cited computer scientist. The discussion covers the current state and future of artificial intelligence, its potential impact on industries and society, and the history of money and cryptocurrencies through Cash App's usage in sending money, buying Bitcoin, and investing in stocks. The episode explores differences between human brain and AI neural networks, focusing on spiking neural networks, simulation using spikes for effective function, back propagation, deep learning, cost functions, supervised learning, and Generative Adversarial Networks (GANs). It also discusses the convergence of reinforcement learning and supervised learning within AI, incorporating large-scale knowledge bases into neural networks, shared principles among different AI domains, and the possibility of a unifying architecture for computer vision similar to transformers in NLP. The podcast delves into challenges and potential timelines for reaching human-level benchmarks in language understanding and visual perception in AI, the effectiveness of neural networks, empirical evidence in understanding evolutionary processes and AI advancements, and the connection between deep learning, biology, and physics as a geometric mean of these disciplines. The episode also discusses the future of deep learning research, breakthroughs in neural networks' size, regularization techniques like early stopping, high-dimensional data overfitting, self-awareness for neural networks, interpretability methods, human memory processing compared to neural networks, and the role of non-recurrence architecture in AI success rates.\n",
      "## End of Summary\n",
      "\n",
      "Clearness evaluation score for episode 94\n",
      "[{'text': 'Somewhat | The summary covers a wide range of topics related to deep learning and artificial intelligence, but it may be overwhelming for someone unfamiliar with these concepts. It could benefit from more organization and clarity in presenting the main points.'}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for episode in episodes:\n",
    "\n",
    "    with open(f\"./predicted/podcast_summaries_ollama_gemma_{episode}.json\") as f: \n",
    "        json_data = json.load(f)\n",
    "        summarized_content = json_data['final_summary']\n",
    "\n",
    "    eval_input_data = [\n",
    "        {\n",
    "            'summary': summarized_content,        \n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print()\n",
    "    print(\"## Summary\")\n",
    "    print(summarized_content)\n",
    "    print(\"## End of Summary\")\n",
    "    \n",
    "    eval_prompt = PromptTemplate(template=eval_prompt_template, input_variables=[\"summary\"])\n",
    "\n",
    "    # Define the LLMs\n",
    "    map_llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo-1106')\n",
    "\n",
    "    map_llm_chain = LLMChain(llm = map_llm, prompt = eval_prompt)\n",
    "\n",
    "    map_llm_chain_input = eval_input_data\n",
    "    # Run the input through the LLM chain (works in parallel)\n",
    "    map_llm_chain_results = map_llm_chain.apply(map_llm_chain_input)\n",
    "    print()\n",
    "\n",
    "    print(f\"Clearness evaluation score for episode {episode}\")\n",
    "    print(map_llm_chain_results)\n",
    "    print(\"##############################################\")\n",
    "    print(\"##############################################\")\n",
    "    print()\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d228f8d1b134e326a52396b2016d42a4e7c84199cf5eb27412c1836171e03131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
