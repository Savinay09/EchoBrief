{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "V-tUvCW7zwHu",
    "outputId": "d8b92234-7001-44ba-9563-de57feb678fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bizon/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f72be7482d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "# df = pd.read_csv('tech_file.csv')\n",
    "# orig_txt = df['transcript'][25]\n",
    "import torch\n",
    "import random\n",
    "from evaluate import load\n",
    "\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25.0/25.0 [00:00<00:00, 66.1kB/s]\n",
      "config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 482/482 [00:00<00:00, 1.71MB/s]\n",
      "vocab.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 899k/899k [00:00<00:00, 1.37MB/s]\n",
      "merges.txt: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 814kB/s]\n",
      "model.safetensors: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.42G/1.42G [21:33<00:00, 1.10MB/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bertscore = load(\"bertscore\")\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.9999999403953552, 1.0],\n",
       " 'recall': [0.9999999403953552, 1.0],\n",
       " 'f1': [0.9999999403953552, 1.0],\n",
       " 'hashcode': 'roberta-large_L17_no-idf_version=0.3.9(hug_trans=4.31.0)'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "podcast_data = []\n",
    "row_num = 0\n",
    "with open('../summarize/vtt_data.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='|')\n",
    "    for row in reader:\n",
    "        row_num += 1\n",
    "        \n",
    "        if row_num == 1:\n",
    "            continue\n",
    "            \n",
    "        filename = row[5]\n",
    "        if not filename.endswith(\"_large.vtt\"):\n",
    "            continue\n",
    "\n",
    "        podcast = {    \n",
    "            \"episode_index\": row[0],    \n",
    "            \"guest\": row[1],\n",
    "            \"episode_name\": row[2],\n",
    "            \"host_name\": row[3],\n",
    "            \"episode_number\": row[4],\n",
    "            \"transcript\": row[6],\n",
    "            \"duration\": row[7],\n",
    "        }\n",
    "        podcast_data.append(podcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_summaries = {\n",
    "    \"12\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_12_benchmark.json\",\n",
    "    \"22\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_22_benchmark.json\",\n",
    "    \"23\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_23_benchmark.json\",\n",
    "    \"94\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_94_benchmark.json\",\n",
    "}\n",
    "\n",
    "keypoints_summaries = {\n",
    "    \"12\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_12_stage3_extractkeypoints_v2b4.json\",\n",
    "    \"22\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_22_stage3_extractkeypoints_v2b4.json\",\n",
    "    \"23\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_23_stage3_extractkeypoints_v2b4.json\",\n",
    "    \"94\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_94_stage3_extractkeypoints_v2b4_ep94only.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1HHVBn6kIRk",
    "outputId": "ea38fca8-d136-4e51-efa9-a96c407381d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating score for episode: 12\n",
      "Calculating score for episode: 22\n",
      "Calculating score for episode: 23\n",
      "Calculating score for episode: 94\n",
      "benchmark_results:\n",
      "{'precision': [0.8271299600601196, 0.8481485843658447, 0.830432653427124, 0.818525493144989], 'recall': [0.8189882040023804, 0.8240691423416138, 0.8178576231002808, 0.8038623332977295], 'f1': [0.8230389952659607, 0.8359354734420776, 0.8240971565246582, 0.8111276030540466], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.9(hug_trans=4.31.0)'}\n",
      "keypoint_results:\n",
      "{'precision': [0.8322412967681885, 0.8500759601593018, 0.8304056525230408, 0.8181145191192627], 'recall': [0.8268346786499023, 0.8384329080581665, 0.8199012875556946, 0.8053003549575806], 'f1': [0.8295291662216187, 0.8442143201828003, 0.8251200914382935, 0.8116568326950073], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.9(hug_trans=4.31.0)'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transcripts = []\n",
    "benchmarks = []\n",
    "keypoints = []\n",
    "\n",
    "count = 0\n",
    "for podcast in podcast_data:\n",
    "\n",
    "    if int(podcast['episode_number']) != 94 and int(podcast['episode_number']) != 23 and \\\n",
    "       int(podcast['episode_number']) != 12 and int(podcast['episode_number']) != 22:\n",
    "#         print(f\"episode {podcast['episode_number']} already processed. skip\")\n",
    "        continue\n",
    "    \n",
    "    transcripts.append(podcast['transcript'])\n",
    "    \n",
    "    print(f\"Calculating score for episode: {podcast['episode_number']}\")    \n",
    "    summary = benchmark_summaries[podcast['episode_number']] \n",
    "    \n",
    "    summary_json = None\n",
    "    with open(summary) as f:\n",
    "        summary_json = json.load(f)\n",
    "    \n",
    "    benchmarks.append(summary_json['final_summary'])\n",
    "    \n",
    "    # keypoints\n",
    "    summary = keypoints_summaries[podcast['episode_number']] \n",
    "    \n",
    "    summary_json = None\n",
    "    with open(summary) as f:\n",
    "        summary_json = json.load(f)\n",
    "    \n",
    "    keypoints.append(summary_json['final_summary'])\n",
    "\n",
    "    \n",
    "benchmark_results = bertscore.compute(predictions=benchmarks, references=transcripts, lang=\"en\")\n",
    "    \n",
    "print(\"benchmark_results:\")\n",
    "print(benchmark_results)\n",
    "\n",
    "keypoint_results = bertscore.compute(predictions=keypoints, references=transcripts, lang=\"en\")\n",
    "\n",
    "print(\"keypoint_results:\")\n",
    "print(keypoint_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NE benchmark_results_avg_precision: 0.8311\n",
      "NE benchmark_results_avg_recall: 0.8162\n",
      "NE keypoint_results_avg_precision: 0.8327\n",
      "NE keypoint_results_avg_recall: 0.8226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "benchmark_results_avg_precision = sum(benchmark_results['precision'])/len(benchmark_results['precision'])\n",
    "benchmark_results_avg_recall = sum(benchmark_results['recall'])/len(benchmark_results['recall'])\n",
    "\n",
    "print(f\"NE benchmark_results_avg_precision: {benchmark_results_avg_precision:.4f}\")\n",
    "print(f\"NE benchmark_results_avg_recall: {benchmark_results_avg_recall:.4f}\")\n",
    "\n",
    "keypoint_results_avg_precision = sum(keypoint_results['precision'])/len(keypoint_results['precision'])\n",
    "keypoint_results_avg_recall = sum(keypoint_results['recall'])/len(keypoint_results['recall'])\n",
    "\n",
    "print(f\"NE keypoint_results_avg_precision: {keypoint_results_avg_precision:.4f}\")\n",
    "print(f\"NE keypoint_results_avg_recall: {keypoint_results_avg_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
