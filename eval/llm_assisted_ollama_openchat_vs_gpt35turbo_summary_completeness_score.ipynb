{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from langchain import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "episodes = [22,23,79,94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt_template = \"\"\"You are comparing predicted_summary and baseline_summary and \n",
    "trying to determine if the text1 is complete relative to text2. \n",
    "\n",
    "Here is the data:\n",
    "[BEGIN DATA]\n",
    "************\n",
    "[predicted_summary]: {predicted_summary}\n",
    "************\n",
    "[baseline_summary]: {baseline_summary}\n",
    "[END DATA]\n",
    "\n",
    "\n",
    "Your response must be either All, Most, Some, or None. Your response should not contain any text\n",
    "or characters aside from that.\n",
    "\n",
    "The string All means that predicted_summary contains all the facts that are present in baseline_summary.\n",
    "\n",
    "The string Most means that predicted_summary contains most of the facts that are present in baseline_summary.\n",
    "\n",
    "The string Some means that predicted_summary contains some of the facts that are present in baseline_summary.\n",
    "\n",
    "The string None means that predicted_summary contains none of the facts that are present in baseline_summary.\n",
    "\n",
    "You response should also contain reasons behind your evaluation.\n",
    "\n",
    "Return your answer in the following format:\n",
    "  All/Most/Som/None | reasons...\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######  Episode 22\n",
      "## Predicted Summary\n",
      "In this podcast, Rajat Manga, director of Google's TensorFlow team, discusses the evolution of TensorFlow from a software library to an ecosystem of tools for deploying machine learning. The decision to open source TensorFlow is seen as a defining moment in the tech industry, inspiring open innovation and the exchange of ideas. The podcast explores the early days of Google Brain and the potential of deep learning, as well as the impact of scaling data and computing power on the performance of machine learning models. It also discusses the development of TensorFlow, including the considerations for use cases and hardware support.\n",
      "\n",
      "The podcast also explores the customization of handcrafted code and internal libraries for machine learning, focusing on Theano, Caffe, and TensorFlow 2.0 at Google. It discusses the decision-making process behind choosing a machine learning library, the evolution of using graphs in machine learning, and the unexpected popularity and growth of deep learning. The podcast also highlights the role of deep learning in enterprise, the stability and usability of older models, and the challenges of implementing machine learning in various industries.\n",
      "\n",
      "Additionally, the podcast discusses the decision to simplify and integrate Keras into TensorFlow, making it easier for users to navigate and choose the right API for their needs. It explores the decision-making process in open source projects, the evolution of Keras and its relationship with TensorFlow, and the developer's role in the community. The integration of Keras into TensorFlow has simplified the use of TensorFlow for beginners and enterprises, making transfer learning and basic use cases much simpler.\n",
      "\n",
      "The podcast also delves into the competition between TensorFlow and PyTorch, emphasizing the importance of learning from the competition to improve their own platform. It discusses the integration of eager execution in TensorFlow 2.0 and its impact on development, as well as the potential for increased performance and efficiency. The restructuring of TensorFlow into more modular pieces is also highlighted, with an emphasis on making the ecosystem more accessible for collaboration and development.\n",
      "\n",
      "Furthermore, the podcast explores the potential evolution of hardware accelerators and TensorFlow, including the possibility of training with four bits instead of 32 bits and the coevolution of TPU and TensorFlow. The conversation also touches on making TensorFlow more accessible for beginners and the challenges they may face. It also explores the challenges and solutions for beginners using TensorFlow, the potential for major corporations to utilize TensorFlow, and the factors that contribute to the growth and success of open source communities, using TensorFlow as a case study. The speaker also discusses the future of machine learning and AI technologies, predicting the continued prominence of certain technologies and potential advancements in the next five years.\n",
      "\n",
      "The podcast also emphasizes the impact of cohesive teams and motivated individuals in cutting-edge technology projects, using Google's hiring process and the development of TensorFlow as examples. It emphasizes the importance of team cohesion, motivation, and culture fit in product development, as well as the balance between speed and quality in meeting deadlines. The conversation also delves into the value of quick iteration and experimentation in software development, highlighting the ongoing development and upcoming release of TensorFlow 2.0.\n",
      "\n",
      "Finally, the podcast explores the potential of search ads to connect users with what they need, the role of machine learning in improving user experience, and the challenges and opportunities in the world of search ads. It discusses the importance of aligning ads with user needs and maintaining a minimum quality level, as well as the future of paid content on the internet. The conversation also delves into the use of technology like TPUs and TensorFlow in education, and the benefits and limitations of using cloud computing for machine learning. The podcast provides valuable insights for beginners interested in machine learning and TensorFlow.\n",
      "## End of Predicted Summary\n",
      "\n",
      "## Baseline Summary\n",
      " This podcast explores the history and impact of TensorFlow 2.0, from its origins in Google Brain to its current status as an open-source ecosystem. The discussion covers key milestones like the birth of deep learning at Google, the rise of TensorFlow and Torch libraries, and the integration with Google Cloud. It delves into how TensorFlow has evolved to support various platforms and hardware, shaping AI advancements across industries.\n",
      "\n",
      "The podcast also discusses customized machine learning solutions such as Theano and Caffe, the growth of deep learning technology, and the importance of comprehensive documentation for making deep learning accessible to developers. It highlights transformer models, reinforcement learning, and generative adversarial networks pushing AI innovation's boundaries and their practicality in hobbyists and enterprises.\n",
      "\n",
      "The development of Keras 2.0 and its goal of simplifying API integration and usage is also explored. The growth of the TensorFlow ecosystem from Andrej Karpathy's ComNetJS to TensorFlow.js for both backend and frontend development, TensorFlow Extended for enhanced data pipelines, and TensorFlow Lite for mobile applications is discussed.\n",
      "\n",
      "The podcast delves into the two primary directions for advancing machine learning research and application using TensorFlow: pushing the boundaries of innovation and making advancements accessible to individuals outside academia. It also discusses the expanding ecosystem of machine learning across devices, challenges in TensorFlow.js integration, scaling TensorFlow while maintaining compatibility, and embracing change for designing with a clean slate.\n",
      "\n",
      "The podcast explores the evolution of TensorFlow and PyTorch, discussing their impact on graph processing and machine learning development, the benefits of competition and the iterative process that led to advancements like eager execution in TensorFlow 2.0. It also looks forward to future innovations in distributed computing and GPU operations.\n",
      "\n",
      "Lastly, the podcast discusses Google's journey from a bottom-up organization, the importance of team health, alignment, and individual superstars in AI projects like TensorFlow, and insights on achieving a balance between engineering excellence and team fit across various projects and teams at Google.\n",
      "## End of Baseline Summary\n",
      "\n",
      "Completeness evaluation score for episode 22\n",
      "[{'text': 'Most | The predicted_summary covers most of the key points and topics discussed in the baseline_summary, such as the evolution of TensorFlow, the integration of Keras, the competition between TensorFlow and PyTorch, and the impact of cohesive teams and motivated individuals in technology projects. However, there are some additional details and topics in the baseline_summary that are not present in the predicted_summary, such as the potential of search ads, the role of machine learning in improving user experience, and the use of technology like TPUs and TensorFlow in education.'}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n",
      "#######  Episode 23\n",
      "## Predicted Summary\n",
      "In this podcast, Rajat Manga, director of Google's TensorFlow team, discusses the evolution of TensorFlow from a software library to an ecosystem of tools for deploying machine learning. The decision to open source TensorFlow is seen as a defining moment in the tech industry, inspiring open innovation and the exchange of ideas. The podcast explores the early days of Google Brain and the potential of deep learning, as well as the impact of scaling data and computing power on the performance of machine learning models. It also discusses the development of TensorFlow, including the considerations for use cases and hardware support.\n",
      "\n",
      "The podcast also explores the customization of handcrafted code and internal libraries for machine learning, focusing on Theano, Caffe, and TensorFlow 2.0 at Google. It discusses the decision-making process behind choosing a machine learning library, the evolution of using graphs in machine learning, and the unexpected popularity and growth of deep learning. The podcast also highlights the role of deep learning in enterprise, the stability and usability of older models, and the challenges of implementing machine learning in various industries.\n",
      "\n",
      "Additionally, the podcast discusses the decision to simplify and integrate Keras into TensorFlow, making it easier for users to navigate and choose the right API for their needs. It explores the decision-making process in open source projects, the evolution of Keras and its relationship with TensorFlow, and the developer's role in the community. The integration of Keras into TensorFlow has simplified the use of TensorFlow for beginners and enterprises, making transfer learning and basic use cases much simpler.\n",
      "\n",
      "The podcast also delves into the competition between TensorFlow and PyTorch, emphasizing the importance of learning from the competition to improve their own platform. It discusses the integration of eager execution in TensorFlow 2.0 and its impact on development, as well as the potential for increased performance and efficiency. The restructuring of TensorFlow into more modular pieces is also highlighted, with an emphasis on making the ecosystem more accessible for collaboration and development.\n",
      "\n",
      "Furthermore, the podcast explores the potential evolution of hardware accelerators and TensorFlow, including the possibility of training with four bits instead of 32 bits and the coevolution of TPU and TensorFlow. The conversation also touches on making TensorFlow more accessible for beginners and the challenges they may face. It also explores the challenges and solutions for beginners using TensorFlow, the potential for major corporations to utilize TensorFlow, and the factors that contribute to the growth and success of open source communities, using TensorFlow as a case study. The speaker also discusses the future of machine learning and AI technologies, predicting the continued prominence of certain technologies and potential advancements in the next five years.\n",
      "\n",
      "The podcast also emphasizes the impact of cohesive teams and motivated individuals in cutting-edge technology projects, using Google's hiring process and the development of TensorFlow as examples. It emphasizes the importance of team cohesion, motivation, and culture fit in product development, as well as the balance between speed and quality in meeting deadlines. The conversation also delves into the value of quick iteration and experimentation in software development, highlighting the ongoing development and upcoming release of TensorFlow 2.0.\n",
      "\n",
      "Finally, the podcast explores the potential of search ads to connect users with what they need, the role of machine learning in improving user experience, and the challenges and opportunities in the world of search ads. It discusses the importance of aligning ads with user needs and maintaining a minimum quality level, as well as the future of paid content on the internet. The conversation also delves into the use of technology like TPUs and TensorFlow in education, and the benefits and limitations of using cloud computing for machine learning. The podcast provides valuable insights for beginners interested in machine learning and TensorFlow.\n",
      "## End of Predicted Summary\n",
      "\n",
      "## Baseline Summary\n",
      " This podcast explores the evolution of AI-generated poetry and emotional expression in technology, focusing on crafting conversational AI personalities and their potential to revolutionize digital art. It delves into how artificial intelligence is transforming the creative process through realistic simulations, automating repetitive tasks, and making art more accessible for expression and novelty. The podcast also discusses the integration of AI in design, raising questions about the role of human artists and designers as they evolve to become art directors or conceptual artists with computers as their creative partners.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## End of Baseline Summary\n",
      "\n",
      "Completeness evaluation score for episode 23\n",
      "[{'text': 'Some | The predicted_summary covers some aspects of the baseline_summary, such as the discussion of AI in creative processes and the intersection of technology and creativity. However, it does not mention specific details like Dr. Gavin Miller, Adobe Research, or the specific examples of AI applications in creating images, video, audio, and language. Therefore, it only covers some of the content present in the baseline_summary.'}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n",
      "#######  Episode 79\n",
      "## Predicted Summary\n",
      "In this podcast, Rajat Manga, director of Google's TensorFlow team, discusses the evolution of TensorFlow from a software library to an ecosystem of tools for deploying machine learning. The decision to open source TensorFlow is seen as a defining moment in the tech industry, inspiring open innovation and the exchange of ideas. The podcast explores the early days of Google Brain and the potential of deep learning, as well as the impact of scaling data and computing power on the performance of machine learning models. It also discusses the development of TensorFlow, including the considerations for use cases and hardware support.\n",
      "\n",
      "The podcast also explores the customization of handcrafted code and internal libraries for machine learning, focusing on Theano, Caffe, and TensorFlow 2.0 at Google. It discusses the decision-making process behind choosing a machine learning library, the evolution of using graphs in machine learning, and the unexpected popularity and growth of deep learning. The podcast also highlights the role of deep learning in enterprise, the stability and usability of older models, and the challenges of implementing machine learning in various industries.\n",
      "\n",
      "Additionally, the podcast discusses the decision to simplify and integrate Keras into TensorFlow, making it easier for users to navigate and choose the right API for their needs. It explores the decision-making process in open source projects, the evolution of Keras and its relationship with TensorFlow, and the developer's role in the community. The integration of Keras into TensorFlow has simplified the use of TensorFlow for beginners and enterprises, making transfer learning and basic use cases much simpler.\n",
      "\n",
      "The podcast also delves into the competition between TensorFlow and PyTorch, emphasizing the importance of learning from the competition to improve their own platform. It discusses the integration of eager execution in TensorFlow 2.0 and its impact on development, as well as the potential for increased performance and efficiency. The restructuring of TensorFlow into more modular pieces is also highlighted, with an emphasis on making the ecosystem more accessible for collaboration and development.\n",
      "\n",
      "Furthermore, the podcast explores the potential evolution of hardware accelerators and TensorFlow, including the possibility of training with four bits instead of 32 bits and the coevolution of TPU and TensorFlow. The conversation also touches on making TensorFlow more accessible for beginners and the challenges they may face. It also explores the challenges and solutions for beginners using TensorFlow, the potential for major corporations to utilize TensorFlow, and the factors that contribute to the growth and success of open source communities, using TensorFlow as a case study. The speaker also discusses the future of machine learning and AI technologies, predicting the continued prominence of certain technologies and potential advancements in the next five years.\n",
      "\n",
      "The podcast also emphasizes the impact of cohesive teams and motivated individuals in cutting-edge technology projects, using Google's hiring process and the development of TensorFlow as examples. It emphasizes the importance of team cohesion, motivation, and culture fit in product development, as well as the balance between speed and quality in meeting deadlines. The conversation also delves into the value of quick iteration and experimentation in software development, highlighting the ongoing development and upcoming release of TensorFlow 2.0.\n",
      "\n",
      "Finally, the podcast explores the potential of search ads to connect users with what they need, the role of machine learning in improving user experience, and the challenges and opportunities in the world of search ads. It discusses the importance of aligning ads with user needs and maintaining a minimum quality level, as well as the future of paid content on the internet. The conversation also delves into the use of technology like TPUs and TensorFlow in education, and the benefits and limitations of using cloud computing for machine learning. The podcast provides valuable insights for beginners interested in machine learning and TensorFlow.\n",
      "## End of Predicted Summary\n",
      "\n",
      "## Baseline Summary\n",
      " In this podcast episode, renowned theoretical physicist Lee Smolin shares his critiques on physics and string theory while exploring beyond the quantum. The discussion delves into the connection between artificial intelligence and theoretical physics, emphasizing the importance of understanding first principles. The history of money is also explored, highlighting the significance of historical context in today's world. The podcast discusses the subjective nature of reality perception, arguing that the scientific method is not universally applicable and that reality is constantly changing. It delves into the importance of ethics and rigorous training in shaping a scientist's mindset while emphasizing repeatability and experimentation for validating theories within the scientific community. The podcast also investigates the impact of self-confidence on scientific innovation, using examples from physicists like Einstein, Newton, and Galileo.\n",
      "## End of Baseline Summary\n",
      "\n",
      "Completeness evaluation score for episode 79\n",
      "[{'text': 'Some | The predicted_summary covers some similar topics as the baseline_summary, such as theoretical physics, the nature of reality, and the impact of self-confidence on scientific innovation. However, the predicted_summary does not cover the specific discussions on quantum gravity, string theory, the many worlds interpretation, and the work of specific physicists like David Wallace and Sean Carroll, which are present in the baseline_summary. Therefore, the predicted_summary does not contain all the facts present in the baseline_summary.'}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n",
      "#######  Episode 94\n",
      "## Predicted Summary\n",
      "In this podcast, Rajat Manga, director of Google's TensorFlow team, discusses the evolution of TensorFlow from a software library to an ecosystem of tools for deploying machine learning. The decision to open source TensorFlow is seen as a defining moment in the tech industry, inspiring open innovation and the exchange of ideas. The podcast explores the early days of Google Brain and the potential of deep learning, as well as the impact of scaling data and computing power on the performance of machine learning models. It also discusses the development of TensorFlow, including the considerations for use cases and hardware support.\n",
      "\n",
      "The podcast also explores the customization of handcrafted code and internal libraries for machine learning, focusing on Theano, Caffe, and TensorFlow 2.0 at Google. It discusses the decision-making process behind choosing a machine learning library, the evolution of using graphs in machine learning, and the unexpected popularity and growth of deep learning. The podcast also highlights the role of deep learning in enterprise, the stability and usability of older models, and the challenges of implementing machine learning in various industries.\n",
      "\n",
      "Additionally, the podcast discusses the decision to simplify and integrate Keras into TensorFlow, making it easier for users to navigate and choose the right API for their needs. It explores the decision-making process in open source projects, the evolution of Keras and its relationship with TensorFlow, and the developer's role in the community. The integration of Keras into TensorFlow has simplified the use of TensorFlow for beginners and enterprises, making transfer learning and basic use cases much simpler.\n",
      "\n",
      "The podcast also delves into the competition between TensorFlow and PyTorch, emphasizing the importance of learning from the competition to improve their own platform. It discusses the integration of eager execution in TensorFlow 2.0 and its impact on development, as well as the potential for increased performance and efficiency. The restructuring of TensorFlow into more modular pieces is also highlighted, with an emphasis on making the ecosystem more accessible for collaboration and development.\n",
      "\n",
      "Furthermore, the podcast explores the potential evolution of hardware accelerators and TensorFlow, including the possibility of training with four bits instead of 32 bits and the coevolution of TPU and TensorFlow. The conversation also touches on making TensorFlow more accessible for beginners and the challenges they may face. It also explores the challenges and solutions for beginners using TensorFlow, the potential for major corporations to utilize TensorFlow, and the factors that contribute to the growth and success of open source communities, using TensorFlow as a case study. The speaker also discusses the future of machine learning and AI technologies, predicting the continued prominence of certain technologies and potential advancements in the next five years.\n",
      "\n",
      "The podcast also emphasizes the impact of cohesive teams and motivated individuals in cutting-edge technology projects, using Google's hiring process and the development of TensorFlow as examples. It emphasizes the importance of team cohesion, motivation, and culture fit in product development, as well as the balance between speed and quality in meeting deadlines. The conversation also delves into the value of quick iteration and experimentation in software development, highlighting the ongoing development and upcoming release of TensorFlow 2.0.\n",
      "\n",
      "Finally, the podcast explores the potential of search ads to connect users with what they need, the role of machine learning in improving user experience, and the challenges and opportunities in the world of search ads. It discusses the importance of aligning ads with user needs and maintaining a minimum quality level, as well as the future of paid content on the internet. The conversation also delves into the use of technology like TPUs and TensorFlow in education, and the benefits and limitations of using cloud computing for machine learning. The podcast provides valuable insights for beginners interested in machine learning and TensorFlow.\n",
      "## End of Predicted Summary\n",
      "\n",
      "## Baseline Summary\n",
      " In this podcast episode, Ilya Sutskever, co-founder and Chief Scientist at OpenAI, shares insights on deep learning, intelligence, and life as a highly cited computer scientist. The discussion covers the current state and future of artificial intelligence, its potential impact on industries and society, and the history of money and cryptocurrencies through Cash App's usage in sending money, buying Bitcoin, and investing in stocks. The episode explores differences between human brain and AI neural networks, focusing on spiking neural networks, simulation using spikes for effective function, back propagation, deep learning, cost functions, supervised learning, and Generative Adversarial Networks (GANs). It also discusses the convergence of reinforcement learning and supervised learning within AI, incorporating large-scale knowledge bases into neural networks, shared principles among different AI domains, and the possibility of a unifying architecture for computer vision similar to transformers in NLP. The podcast delves into challenges and potential timelines for reaching human-level benchmarks in language understanding and visual perception in AI, the effectiveness of neural networks, empirical evidence in understanding evolutionary processes and AI advancements, and the connection between deep learning, biology, and physics as a geometric mean of these disciplines. The episode also discusses the future of deep learning research, breakthroughs in neural networks' size, regularization techniques like early stopping, high-dimensional data overfitting, self-awareness for neural networks, interpretability methods, human memory processing compared to neural networks, and the role of non-recurrence architecture in AI success rates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## End of Baseline Summary\n",
      "\n",
      "Completeness evaluation score for episode 94\n",
      "[{'text': \"Some | The predicted_summary covers some similar topics as the baseline_summary, such as the future of artificial intelligence, the intersection of AI and finance, the evolution of neural networks, and the potential for unification between reinforcement learning and supervised learning. However, the predicted_summary also includes additional topics not mentioned in the baseline_summary, such as the history of money and cryptocurrencies, differences between human brain and AI neural networks, and breakthroughs in neural networks' size. Therefore, while there are some similarities, the predicted_summary does not cover all the same facts as the baseline_summary.\"}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for episode in episodes:\n",
    "\n",
    "    with open(f\"./predicted/podcast_summaries_ollama_openchat_{episode}_v3.json\") as f: \n",
    "        json_data = json.load(f)\n",
    "        summarized_content = json_data['final_summary']\n",
    "\n",
    "    with open(f\"./baseline/podcast_summaries_openai_gpt35turbo_{episode}_v2.json\") as f: \n",
    "        json_data = json.load(f)\n",
    "        baseline_summary = json_data['final_summary']\n",
    "\n",
    "    eval_input_data = [\n",
    "        {\n",
    "            'predicted_summary': summarized_content,   \n",
    "            'baseline_summary': baseline_summary,     \n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"#######  Episode {episode}\")\n",
    "    print(\"## Predicted Summary\")\n",
    "    print(baseline_transcript)\n",
    "    print(\"## End of Predicted Summary\")\n",
    "    \n",
    "    print()\n",
    "    print(\"## Baseline Summary\")\n",
    "    print(summarized_content)\n",
    "    \n",
    "    eval_prompt = PromptTemplate(template=eval_prompt_template, input_variables=[\"predicted_summary\", \"baseline_summary\"])\n",
    "\n",
    "    # Define the LLMs\n",
    "    map_llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo-1106')\n",
    "\n",
    "    map_llm_chain = LLMChain(llm = map_llm, prompt = eval_prompt)\n",
    "\n",
    "    map_llm_chain_input = eval_input_data\n",
    "    # Run the input through the LLM chain (works in parallel)\n",
    "    map_llm_chain_results = map_llm_chain.apply(map_llm_chain_input)\n",
    "    print(\"## End of Baseline Summary\")\n",
    "    print()\n",
    "\n",
    "    print(f\"Completeness evaluation score for episode {episode}\")\n",
    "    print(map_llm_chain_results)\n",
    "    print(\"##############################################\")\n",
    "    print(\"##############################################\")\n",
    "    print()\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d228f8d1b134e326a52396b2016d42a4e7c84199cf5eb27412c1836171e03131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
