{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "V-tUvCW7zwHu",
    "outputId": "d8b92234-7001-44ba-9563-de57feb678fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff0bbfbc330>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "# df = pd.read_csv('tech_file.csv')\n",
    "# orig_txt = df['transcript'][25]\n",
    "import torch\n",
    "import random\n",
    "\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "podcast_data = []\n",
    "row_num = 0\n",
    "with open('../summarize/vtt_data.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='|')\n",
    "    for row in reader:\n",
    "        row_num += 1\n",
    "        \n",
    "        if row_num == 1:\n",
    "            continue\n",
    "            \n",
    "        filename = row[5]\n",
    "        if not filename.endswith(\"_large.vtt\"):\n",
    "            continue\n",
    "\n",
    "        podcast = {    \n",
    "            \"episode_index\": row[0],    \n",
    "            \"guest\": row[1],\n",
    "            \"episode_name\": row[2],\n",
    "            \"host_name\": row[3],\n",
    "            \"episode_number\": row[4],\n",
    "            \"transcript\": row[6],\n",
    "            \"duration\": row[7],\n",
    "        }\n",
    "        podcast_data.append(podcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark_summaries = {\n",
    "#     \"12\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_12_benchmark.json\",\n",
    "#     \"22\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_22_benchmark.json\",\n",
    "#     \"23\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_23_benchmark.json\",\n",
    "#     \"94\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_94_benchmark.json\",\n",
    "# }\n",
    "\n",
    "# keypoints_summaries = {\n",
    "#     \"12\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_12_stage3_extractkeypoints_v2b4.json\",\n",
    "#     \"22\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_22_stage3_extractkeypoints_v2b4.json\",\n",
    "#     \"23\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_23_stage3_extractkeypoints_v2b4.json\",\n",
    "#     \"94\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_94_stage3_extractkeypoints_v2b4_ep94only.json\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1HHVBn6kIRk",
    "outputId": "ea38fca8-d136-4e51-efa9-a96c407381d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating score for episode: 3\n",
      "Benchmark:\n",
      "NE Precision: 0.67\n",
      "NE Recall: 0.16\n",
      "Keypoints:\n",
      "NE Precision: 0.55\n",
      "NE Recall: 0.12\n",
      "==============================================\n",
      "Calculating score for episode: 4\n",
      "Benchmark:\n",
      "NE Precision: 1.00\n",
      "NE Recall: 0.04\n",
      "Keypoints:\n",
      "NE Precision: 0.87\n",
      "NE Recall: 0.27\n",
      "==============================================\n",
      "Calculating score for episode: 5\n",
      "Benchmark:\n",
      "NE Precision: 0.71\n",
      "NE Recall: 0.13\n",
      "Keypoints:\n",
      "NE Precision: 0.75\n",
      "NE Recall: 0.19\n",
      "==============================================\n",
      "Calculating score for episode: 6\n",
      "Benchmark:\n",
      "NE Precision: 0.76\n",
      "NE Recall: 0.16\n",
      "Keypoints:\n",
      "NE Precision: 0.60\n",
      "NE Recall: 0.07\n",
      "==============================================\n",
      "Calculating score for episode: 7\n",
      "Benchmark:\n",
      "NE Precision: 0.63\n",
      "NE Recall: 0.06\n",
      "Keypoints:\n",
      "NE Precision: 0.77\n",
      "NE Recall: 0.08\n",
      "==============================================\n",
      "Calculating score for episode: 9\n",
      "Benchmark:\n",
      "NE Precision: 0.44\n",
      "NE Recall: 0.04\n",
      "Keypoints:\n",
      "NE Precision: 0.67\n",
      "NE Recall: 0.10\n",
      "==============================================\n",
      "Calculating score for episode: 10\n",
      "Benchmark:\n",
      "NE Precision: 0.80\n",
      "NE Recall: 0.05\n",
      "Keypoints:\n",
      "NE Precision: 0.86\n",
      "NE Recall: 0.14\n",
      "==============================================\n",
      "Calculating score for episode: 11\n",
      "Benchmark:\n",
      "NE Precision: 1.00\n",
      "NE Recall: 0.05\n",
      "Keypoints:\n",
      "NE Precision: 0.73\n",
      "NE Recall: 0.06\n",
      "==============================================\n",
      "Calculating score for episode: 13\n",
      "Benchmark:\n",
      "NE Precision: 0.62\n",
      "NE Recall: 0.04\n",
      "Keypoints:\n",
      "NE Precision: 0.78\n",
      "NE Recall: 0.11\n",
      "==============================================\n",
      "Calculating score for episode: 14\n",
      "Benchmark:\n",
      "NE Precision: 0.57\n",
      "NE Recall: 0.04\n",
      "Keypoints:\n",
      "NE Precision: 0.75\n",
      "NE Recall: 0.15\n",
      "==============================================\n",
      "Calculating score for episode: 15\n",
      "Benchmark:\n",
      "NE Precision: 0.62\n",
      "NE Recall: 0.07\n",
      "Keypoints:\n",
      "NE Precision: 0.57\n",
      "NE Recall: 0.11\n",
      "==============================================\n",
      "Calculating score for episode: 17\n",
      "Benchmark:\n",
      "NE Precision: 0.71\n",
      "NE Recall: 0.07\n",
      "Keypoints:\n",
      "NE Precision: 0.79\n",
      "NE Recall: 0.10\n",
      "==============================================\n",
      "Calculating score for episode: 18\n",
      "Benchmark:\n",
      "NE Precision: 0.87\n",
      "NE Recall: 0.25\n",
      "Keypoints:\n",
      "NE Precision: 0.70\n",
      "NE Recall: 0.45\n",
      "==============================================\n",
      "Calculating score for episode: 19\n",
      "Benchmark:\n",
      "NE Precision: 0.83\n",
      "NE Recall: 0.08\n",
      "Keypoints:\n",
      "NE Precision: 0.96\n",
      "NE Recall: 0.18\n",
      "==============================================\n",
      "Calculating score for episode: 20\n",
      "Benchmark:\n",
      "NE Precision: 0.82\n",
      "NE Recall: 0.12\n",
      "Keypoints:\n",
      "NE Precision: 0.78\n",
      "NE Recall: 0.11\n",
      "==============================================\n",
      "Avg Benchmark NE Precision: 0.74\n",
      "Avg Benchmark NE Recall: 0.09\n",
      "Avg Keypoints NE Precision: 0.74\n",
      "Avg Keypoints NE Recall: 0.15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_benchmark_precision = 0\n",
    "total_benchmark_recall = 0\n",
    "\n",
    "total_keypoints_precision = 0\n",
    "total_keypoints_recall = 0\n",
    "\n",
    "# 15 more\n",
    "episodes_number = [\n",
    "    3,4,5,6,7,9,10,11,13,14,15,17,18,19,20\n",
    "]\n",
    "\n",
    "count = 0\n",
    "for podcast in podcast_data:\n",
    "\n",
    "    episode_number = podcast['episode_number']\n",
    "    \n",
    "    if int(episode_number) not in episodes_number:\n",
    "        continue\n",
    "        \n",
    "    count += 1\n",
    "    \n",
    "    print(f\"Calculating score for episode: {podcast['episode_number']}\")    \n",
    "    summary = f\"../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_{episode_number}_benchmark.json\" \n",
    "    \n",
    "    summary_json = None\n",
    "    with open(summary) as f:\n",
    "        summary_json = json.load(f)\n",
    "    \n",
    "    # Process the texts\n",
    "    source_doc = nlp(podcast['transcript'])\n",
    "    \n",
    "    summary_doc = nlp(summary_json['final_summary'])\n",
    "\n",
    "    # Extract entities from both texts\n",
    "    source_entities = set([(ent.text, ent.label_) for ent in source_doc.ents])\n",
    "    summary_entities = set([(ent.text, ent.label_) for ent in summary_doc.ents])\n",
    "\n",
    "    # Calculate correct NEs in summary\n",
    "    correct_entities_in_summary = summary_entities.intersection(source_entities)\n",
    "\n",
    "    # Calculate Precision and Recall\n",
    "    precision = len(correct_entities_in_summary) / len(summary_entities) if summary_entities else 0\n",
    "    recall = len(correct_entities_in_summary) / len(source_entities) if source_entities else 0\n",
    "\n",
    "    total_benchmark_precision += precision\n",
    "    total_benchmark_recall += recall\n",
    "    \n",
    "    print(\"Benchmark:\")\n",
    "    print(f\"NE Precision: {precision:.2f}\")\n",
    "    print(f\"NE Recall: {recall:.2f}\")\n",
    "    \n",
    "    # keypoints\n",
    "    \n",
    "    summary = f\"../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_{episode_number}_stage3_extractkeypoints_v2b4.json\"\n",
    "      \n",
    "    summary_json = None\n",
    "    with open(summary) as f:\n",
    "        summary_json = json.load(f)\n",
    "    \n",
    "    # Process the texts\n",
    "    summary_doc = nlp(summary_json['final_summary'])\n",
    "\n",
    "    # Extract entities from both texts\n",
    "    summary_entities = set([(ent.text, ent.label_) for ent in summary_doc.ents])\n",
    "\n",
    "    # Calculate correct NEs in summary\n",
    "    correct_entities_in_summary = summary_entities.intersection(source_entities)\n",
    "\n",
    "    # Calculate Precision and Recall\n",
    "    precision = len(correct_entities_in_summary) / len(summary_entities) if summary_entities else 0\n",
    "    recall = len(correct_entities_in_summary) / len(source_entities) if source_entities else 0\n",
    "\n",
    "    total_keypoints_precision += precision\n",
    "    total_keypoints_recall += recall\n",
    "    \n",
    "    print(\"Keypoints:\")\n",
    "    print(f\"NE Precision: {precision:.2f}\")\n",
    "    print(f\"NE Recall: {recall:.2f}\")\n",
    "    \n",
    "    print(\"==============================================\")\n",
    "    \n",
    "    \n",
    "# calculate average precision and recall scores\n",
    "\n",
    "\n",
    "print(f\"Avg Benchmark NE Precision: {total_benchmark_precision/count:.2f}\")\n",
    "print(f\"Avg Benchmark NE Recall: {total_benchmark_recall/count:.2f}\")\n",
    "\n",
    "print(f\"Avg Keypoints NE Precision: {total_keypoints_precision/count:.2f}\")\n",
    "print(f\"Avg Keypoints NE Recall: {total_keypoints_recall/count:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
