{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from langchain import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "episodes = [22,23,79,94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt_template = \"\"\"You are comparing predicted_summary and baseline_summary and \n",
    "trying to determine if the predicted_summary is accurate using the baseline_summary as the source of truth.\n",
    "\n",
    "\n",
    "Here is the data:\n",
    "[BEGIN DATA]\n",
    "************\n",
    "[predicted_summary]: {predicted_summary}\n",
    "************\n",
    "[baseline_summary]: {baseline_summary}\n",
    "[END DATA]\n",
    "\n",
    "\n",
    "Your response must be either Very, Most, Somewhat, or Not. Your response should not contain any text\n",
    "or characters aside from that.\n",
    "\n",
    "The string Very means that predicted_summary is a very accurate.\n",
    "\n",
    "The string Mostly means that predicted_summary is a mostly accurate.\n",
    "\n",
    "The string Somewhat means that predicted_summary is a somewhat accurate.\n",
    "\n",
    "The string Not means that predicted_summary is not accurate.\n",
    "\n",
    "You response should also contain reasons behind your evaluation.\n",
    "\n",
    "Return your answer in the following format:\n",
    "  Very/Mostly/Somewhat/Not | reasons...\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######  Episode 22\n",
      "## Predicted Summary\n",
      " This podcast explores the history and impact of TensorFlow 2.0, from its origins in Google Brain to its current status as an open-source ecosystem. The discussion covers key milestones like the birth of deep learning at Google, the rise of TensorFlow and Torch libraries, and the integration with Google Cloud. It delves into how TensorFlow has evolved to support various platforms and hardware, shaping AI advancements across industries.\n",
      "\n",
      "The podcast also discusses customized machine learning solutions such as Theano and Caffe, the growth of deep learning technology, and the importance of comprehensive documentation for making deep learning accessible to developers. It highlights transformer models, reinforcement learning, and generative adversarial networks pushing AI innovation's boundaries and their practicality in hobbyists and enterprises.\n",
      "\n",
      "The development of Keras 2.0 and its goal of simplifying API integration and usage is also explored. The growth of the TensorFlow ecosystem from Andrej Karpathy's ComNetJS to TensorFlow.js for both backend and frontend development, TensorFlow Extended for enhanced data pipelines, and TensorFlow Lite for mobile applications is discussed.\n",
      "\n",
      "The podcast delves into the two primary directions for advancing machine learning research and application using TensorFlow: pushing the boundaries of innovation and making advancements accessible to individuals outside academia. It also discusses the expanding ecosystem of machine learning across devices, challenges in TensorFlow.js integration, scaling TensorFlow while maintaining compatibility, and embracing change for designing with a clean slate.\n",
      "\n",
      "The podcast explores the evolution of TensorFlow and PyTorch, discussing their impact on graph processing and machine learning development, the benefits of competition and the iterative process that led to advancements like eager execution in TensorFlow 2.0. It also looks forward to future innovations in distributed computing and GPU operations.\n",
      "\n",
      "Lastly, the podcast discusses Google's journey from a bottom-up organization, the importance of team health, alignment, and individual superstars in AI projects like TensorFlow, and insights on achieving a balance between engineering excellence and team fit across various projects and teams at Google.\n",
      "## End of Predicted Summary\n",
      "\n",
      "## Baseline Summary\n",
      "In this podcast, Rajat Manga, director of Google's TensorFlow team, discusses the evolution of TensorFlow from a software library to an ecosystem of tools for deploying machine learning. The decision to open source TensorFlow is seen as a defining moment in the tech industry, inspiring open innovation and the exchange of ideas. The podcast explores the early days of Google Brain and the potential of deep learning, as well as the impact of scaling data and computing power on the performance of machine learning models. It also discusses the development of TensorFlow, including the considerations for use cases and hardware support.\n",
      "\n",
      "The podcast also explores the customization of handcrafted code and internal libraries for machine learning, focusing on Theano, Caffe, and TensorFlow 2.0 at Google. It discusses the decision-making process behind choosing a machine learning library, the evolution of using graphs in machine learning, and the unexpected popularity and growth of deep learning. The podcast also highlights the role of deep learning in enterprise, the stability and usability of older models, and the challenges of implementing machine learning in various industries.\n",
      "\n",
      "Additionally, the podcast discusses the decision to simplify and integrate Keras into TensorFlow, making it easier for users to navigate and choose the right API for their needs. It explores the decision-making process in open source projects, the evolution of Keras and its relationship with TensorFlow, and the developer's role in the community. The integration of Keras into TensorFlow has simplified the use of TensorFlow for beginners and enterprises, making transfer learning and basic use cases much simpler.\n",
      "\n",
      "The podcast also delves into the competition between TensorFlow and PyTorch, emphasizing the importance of learning from the competition to improve their own platform. It discusses the integration of eager execution in TensorFlow 2.0 and its impact on development, as well as the potential for increased performance and efficiency. The restructuring of TensorFlow into more modular pieces is also highlighted, with an emphasis on making the ecosystem more accessible for collaboration and development.\n",
      "\n",
      "Furthermore, the podcast explores the potential evolution of hardware accelerators and TensorFlow, including the possibility of training with four bits instead of 32 bits and the coevolution of TPU and TensorFlow. The conversation also touches on making TensorFlow more accessible for beginners and the challenges they may face. It also explores the challenges and solutions for beginners using TensorFlow, the potential for major corporations to utilize TensorFlow, and the factors that contribute to the growth and success of open source communities, using TensorFlow as a case study. The speaker also discusses the future of machine learning and AI technologies, predicting the continued prominence of certain technologies and potential advancements in the next five years.\n",
      "\n",
      "The podcast also emphasizes the impact of cohesive teams and motivated individuals in cutting-edge technology projects, using Google's hiring process and the development of TensorFlow as examples. It emphasizes the importance of team cohesion, motivation, and culture fit in product development, as well as the balance between speed and quality in meeting deadlines. The conversation also delves into the value of quick iteration and experimentation in software development, highlighting the ongoing development and upcoming release of TensorFlow 2.0.\n",
      "\n",
      "Finally, the podcast explores the potential of search ads to connect users with what they need, the role of machine learning in improving user experience, and the challenges and opportunities in the world of search ads. It discusses the importance of aligning ads with user needs and maintaining a minimum quality level, as well as the future of paid content on the internet. The conversation also delves into the use of technology like TPUs and TensorFlow in education, and the benefits and limitations of using cloud computing for machine learning. The podcast provides valuable insights for beginners interested in machine learning and TensorFlow.\n",
      "## End of Baseline Summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bizon/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Truthfulness evaluation score for episode 22\n",
      "[{'text': 'Mostly | The predicted_summary covers many of the same topics and themes as the baseline_summary, but it lacks some specific details and focuses on different aspects of the discussion. Overall, it captures the essence of the podcast but does not align perfectly with the baseline_summary.'}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n",
      "#######  Episode 23\n",
      "## Predicted Summary\n",
      " This podcast explores the evolution of AI-generated poetry and emotional expression in technology, focusing on crafting conversational AI personalities and their potential to revolutionize digital art. It delves into how artificial intelligence is transforming the creative process through realistic simulations, automating repetitive tasks, and making art more accessible for expression and novelty. The podcast also discusses the integration of AI in design, raising questions about the role of human artists and designers as they evolve to become art directors or conceptual artists with computers as their creative partners.\n",
      "## End of Predicted Summary\n",
      "\n",
      "## Baseline Summary\n",
      "Dr. Gavin Miller, head of Adobe Research, discusses the future of Adobe's creative software and the innovative applications of AI in creating images, video, audio, and language. The conversation delves into the balance between technology and creativity, offering insights into the intersection of these two fields. Dr. Miller also shares a humorous poem about dieting and weight loss, reflecting on the deeper meaning behind his poetry and how it fits into his life and career. The podcast explores the ways in which creativity and technology intersect, with a focus on how writing, art, and poetry can contribute to research and work in the tech industry.\n",
      "\n",
      "The podcast explores the importance of AI in understanding and describing concepts from different perspectives, using examples like automatic image captioning and the evolution of 3D computer graphics. It discusses the impact of AI on streamlining creative processes, particularly in image editing and manipulation, and highlights the potential for neural nets to revolutionize image recognition and background removal. The speaker emphasizes the value of robust neural nets that can provide high-quality results with minimal user input, ultimately making workflows more efficient.\n",
      "\n",
      "The podcast also delves into the potential impact of adaptive characters in augmented reality on the broader commercial sphere and the potential benefits of using augmented reality and immersive technology in 3D design. It discusses the importance of internships in research labs, highlighting their role in fostering talent, innovation, and enduring relationships with university departments. The podcast ends with a favorite poem that contemplates mortality and immortality, leaving the listener with a sense of wonder and curiosity about the future.\n",
      "## End of Baseline Summary\n",
      "\n",
      "Truthfulness evaluation score for episode 23\n",
      "[{'text': \"Not | The predicted_summary does not accurately reflect the content of the baseline_summary. The predicted_summary focuses on AI-generated poetry and emotional expression in technology, while the baseline_summary discusses the future of Adobe's creative software, the intersection of technology and creativity, and the impact of AI on streamlining creative processes. The predicted_summary also mentions the integration of AI in design and the potential impact of adaptive characters in augmented reality, which are not mentioned in the baseline_summary. Overall, the predicted_summary does not accurately capture the main points and themes of the baseline_summary.\"}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n",
      "#######  Episode 79\n",
      "## Predicted Summary\n",
      " In this podcast episode, renowned theoretical physicist Lee Smolin shares his critiques on physics and string theory while exploring beyond the quantum. The discussion delves into the connection between artificial intelligence and theoretical physics, emphasizing the importance of understanding first principles. The history of money is also explored, highlighting the significance of historical context in today's world. The podcast discusses the subjective nature of reality perception, arguing that the scientific method is not universally applicable and that reality is constantly changing. It delves into the importance of ethics and rigorous training in shaping a scientist's mindset while emphasizing repeatability and experimentation for validating theories within the scientific community. The podcast also investigates the impact of self-confidence on scientific innovation, using examples from physicists like Einstein, Newton, and Galileo.\n",
      "## End of Predicted Summary\n",
      "\n",
      "## Baseline Summary\n",
      "The podcast features theoretical physicist Lee Smolin discussing his contributions to cosmology, quantum field theory, and his critiques of string theory. It explores the intersection of theoretical physics and AI, delving into the fundamental nature of the universe and the human mind. The conversation challenges listeners to consider the nature of reality and the limits of human understanding, exploring the concept that our human perception constructs our reality. It also discusses the origins of human curiosity, our need to explain the world around us, and the necessity of making fast judgments in order to survive.\n",
      "\n",
      "The podcast explores the concept of realism in physics, discussing the belief in an external world independent of our existence and the possibility of an objective description of fundamental processes. It delves into the deterministic nature of the fundamental laws of physics and the potential for their change, challenging the idea of a fixed and predictable universe. The conversation also explores the impact of self-confidence on the progress of theoretical physics, focusing on the unfinished revolution of Einstein's theories. It discusses the need for additional degrees of freedom, particles, and forces to provide a complete description of each phenomenon, as well as the debate and friendly rivalry between proponents of different quantum mechanics theories, particularly focusing on the many worlds interpretation.\n",
      "\n",
      "The podcast also delves into the challenges of finding a correct approach to quantum gravity, referencing the work of David Wallace and Sean Carroll, and features physicist Andy Straminger discussing the complexities and potential breakthroughs in the field of quantum gravity and string theory. The conversation emphasizes the importance of diverse ideas coming together in the pursuit of scientific and technological innovation.\n",
      "## End of Baseline Summary\n",
      "\n",
      "Truthfulness evaluation score for episode 79\n",
      "[{'text': 'Somewhat | The predicted_summary covers some of the same topics as the baseline_summary, such as theoretical physics, string theory, and the nature of reality. However, the predicted_summary also includes discussions on the history of money, ethics, and the impact of self-confidence on scientific innovation, which are not mentioned in the baseline_summary. Additionally, the predicted_summary does not delve into the same level of detail on specific theories and physicists as the baseline_summary. Therefore, the predicted_summary is only somewhat accurate compared to the baseline_summary.'}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n",
      "#######  Episode 94\n",
      "## Predicted Summary\n",
      " In this podcast episode, Ilya Sutskever, co-founder and Chief Scientist at OpenAI, shares insights on deep learning, intelligence, and life as a highly cited computer scientist. The discussion covers the current state and future of artificial intelligence, its potential impact on industries and society, and the history of money and cryptocurrencies through Cash App's usage in sending money, buying Bitcoin, and investing in stocks. The episode explores differences between human brain and AI neural networks, focusing on spiking neural networks, simulation using spikes for effective function, back propagation, deep learning, cost functions, supervised learning, and Generative Adversarial Networks (GANs). It also discusses the convergence of reinforcement learning and supervised learning within AI, incorporating large-scale knowledge bases into neural networks, shared principles among different AI domains, and the possibility of a unifying architecture for computer vision similar to transformers in NLP. The podcast delves into challenges and potential timelines for reaching human-level benchmarks in language understanding and visual perception in AI, the effectiveness of neural networks, empirical evidence in understanding evolutionary processes and AI advancements, and the connection between deep learning, biology, and physics as a geometric mean of these disciplines. The episode also discusses the future of deep learning research, breakthroughs in neural networks' size, regularization techniques like early stopping, high-dimensional data overfitting, self-awareness for neural networks, interpretability methods, human memory processing compared to neural networks, and the role of non-recurrence architecture in AI success rates.\n",
      "## End of Predicted Summary\n",
      "\n",
      "## Baseline Summary\n",
      "In this podcast, Ilya Sotskever, cofounder and chief scientist of OpenAI, discusses the future of artificial intelligence and its impact on society, with a focus on the intersection of AI and finance, including cryptocurrency and the history of money. The conversation explores the evolution of neural networks, their potential for advancing robotics and STEM education, and the concept of overparameterization in neural networks. The discussion also touches on doubts surrounding the ability to train large neural networks and the breakthroughs that have led to faster training methods.\n",
      "\n",
      "The podcast delves into the connection between the human brain and artificial neural networks, discussing the evolution of deep learning and the analogies between the two. It explores the advantages and disadvantages of artificial neural networks compared to the human brain, as well as the potential resurgence of recurrent neural networks in the field of artificial intelligence. The conversation also explores the concept of maintaining a hidden state as a knowledge base within neural networks and the potential for building large scale knowledge bases within these networks.\n",
      "\n",
      "The podcast also discusses the potential for unification between reinforcement learning and supervised learning, the challenges and similarities between vision and language processing in machine learning, and the potential for a unified system that can handle a wide range of inputs and tasks. It explores the lasting impact of human relationships and the surprising capabilities of artificial intelligence, as well as the challenges and surprising properties of deep learning, including the necessity of compute power, the phenomenon of double descent, the concept of overfitting, and the impact of dimensionality on model performance.\n",
      "\n",
      "The podcast also delves into the theoretical limits of data prediction, the potential for deep neural networks to revolutionize the process of finding programs, and the impact of machine learning and deep learning on solving mathematical problems. It discusses the implications of releasing AI models like GPT2 in stages, the components necessary for creating artificial general intelligence (AGI), and the pursuit of happiness, the potential of machine learning, and the alignment of AI values with human values.\n",
      "## End of Baseline Summary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Truthfulness evaluation score for episode 94\n",
      "[{'text': 'Mostly | The predicted_summary covers many of the same topics and themes as the baseline_summary, but it provides more in-depth and detailed information. However, there are some differences in the specific details and emphasis of the discussion, which may affect the overall accuracy.'}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for episode in episodes:\n",
    "\n",
    "    with open(f\"./predicted/podcast_summaries_ollama_openchat_{episode}_v3.json\") as f: \n",
    "        json_data = json.load(f)\n",
    "        summarized_content = json_data['final_summary']\n",
    "\n",
    "    with open(f\"./baseline/podcast_summaries_openai_gpt35turbo_{episode}_v2.json\") as f: \n",
    "        json_data = json.load(f)\n",
    "        baseline_summary = json_data['final_summary']\n",
    "\n",
    "    eval_input_data = [\n",
    "        {\n",
    "            'predicted_summary': summarized_content,   \n",
    "            'baseline_summary': baseline_summary,     \n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"#######  Episode {episode}\")\n",
    "    print(\"## Predicted Summary\")\n",
    "    print(summarized_content)\n",
    "    print(\"## End of Predicted Summary\")\n",
    "    \n",
    "    print()\n",
    "    print(\"## Baseline Summary\")\n",
    "    print(baseline_summary)\n",
    "    print(\"## End of Baseline Summary\")\n",
    "    \n",
    "    eval_prompt = PromptTemplate(template=eval_prompt_template, input_variables=[\"predicted_summary\", \"baseline_summary\"])\n",
    "\n",
    "    # Define the LLMs\n",
    "    map_llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo-1106')\n",
    "\n",
    "    map_llm_chain = LLMChain(llm = map_llm, prompt = eval_prompt)\n",
    "\n",
    "    map_llm_chain_input = eval_input_data\n",
    "    # Run the input through the LLM chain (works in parallel)\n",
    "    map_llm_chain_results = map_llm_chain.apply(map_llm_chain_input)\n",
    "    print()\n",
    "\n",
    "    print(f\"Truthfulness evaluation score for episode {episode}\")\n",
    "    print(map_llm_chain_results)\n",
    "    print(\"##############################################\")\n",
    "    print(\"##############################################\")\n",
    "    print()\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d228f8d1b134e326a52396b2016d42a4e7c84199cf5eb27412c1836171e03131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
