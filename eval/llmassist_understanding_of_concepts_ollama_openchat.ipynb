{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "\n",
    "from langchain import OpenAI\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.summarize import load_summarize_chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding of key concepts on summarization evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Abstractive and Extractive summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt_template = \"\"\"\n",
    "Answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum. \n",
    "Keep the answer as concise as possible.\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "\n",
    "eval_prompt = PromptTemplate(template=eval_prompt_template, input_variables=[])\n",
    "\n",
    "# Define the LLMs\n",
    "map_llm = ChatOllama(model=\"openchat\")\n",
    "\n",
    "map_llm_chain = LLMChain(llm = map_llm, prompt = eval_prompt)\n",
    "\n",
    "input_data = [\n",
    "    {\n",
    "        'question': \"What is Abstractive Summary?\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"What is Extractive Summary?\"\n",
    "    }    \n",
    "]\n",
    "\n",
    "# Run the input through the LLM chain (works in parallel)\n",
    "map_llm_chain_results = map_llm_chain.apply(input_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ' Abstractive Summary is a technique in natural language processing that generates a condensed and coherent summary of a text by using deep learning models to understand the content and rephrase it in a new form, often significantly different from the original.'},\n",
       " {'text': ' Extractive summary is a method of summarization where relevant information and important points are extracted directly from the original text, without rephrasing or paraphrasing. It involves selecting key sentences and phrases to create a brief representation of the content.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_llm_chain_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization content "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = PromptTemplate(template=eval_prompt_template, input_variables=[])\n",
    "\n",
    "# Define the LLMs\n",
    "map_llm = ChatOllama(model=\"openchat\")\n",
    "\n",
    "map_llm_chain = LLMChain(llm = map_llm, prompt = eval_prompt)\n",
    "\n",
    "input_data = [\n",
    "    {\n",
    "        'question': \"What does it mean for a podcast summary to be concise?\"\n",
    "    }  \n",
    "]\n",
    "\n",
    "# Run the input through the LLM chain (works in parallel)\n",
    "map_llm_chain_results = map_llm_chain.apply(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ' A concise podcast summary is one that provides the essential information about the episode in a brief, clear, and straightforward manner, without unnecessary details or elaboration.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_llm_chain_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = PromptTemplate(template=eval_prompt_template, input_variables=[])\n",
    "\n",
    "# Define the LLMs\n",
    "map_llm = ChatOllama(model=\"openchat\")\n",
    "\n",
    "map_llm_chain = LLMChain(llm = map_llm, prompt = eval_prompt)\n",
    "\n",
    "input_data = [\n",
    "    {\n",
    "        'question': \"What does it mean for a podcast summary to be accurate?\"\n",
    "    }  \n",
    "]\n",
    "\n",
    "# Run the input through the LLM chain (works in parallel)\n",
    "map_llm_chain_results = map_llm_chain.apply(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ' An accurate podcast summary is one that clearly and concisely captures the main points, topics, and themes discussed in the podcast episode, without adding personal opinions or interpretations. It should provide an objective overview of the content, allowing listeners to decide whether they are interested in listening to the full episode based on the summary alone.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_llm_chain_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI has a better answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = PromptTemplate(template=eval_prompt_template, input_variables=[])\n",
    "\n",
    "# Define the LLMs\n",
    "map_llm = ChatOllama(model=\"openchat\")\n",
    "\n",
    "map_llm_chain = LLMChain(llm = map_llm, prompt = eval_prompt)\n",
    "\n",
    "input_data = [\n",
    "    {\n",
    "        'question': \"What does it mean for a podcast summary to be complete?\"\n",
    "    }  \n",
    "]\n",
    "\n",
    "# Run the input through the LLM chain (works in parallel)\n",
    "map_llm_chain_results = map_llm_chain.apply(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ' A complete podcast summary provides a brief and accurate overview of the content, including the main topics discussed, key points or insights shared, and any guests featured. It should give the listener an understanding of what to expect from the episode without revealing too much detail.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_llm_chain_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like it mention guests featured here.. openAI doesn't mention that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = PromptTemplate(template=eval_prompt_template, input_variables=[])\n",
    "\n",
    "# Define the LLMs\n",
    "map_llm = ChatOllama(model=\"openchat\")\n",
    "\n",
    "map_llm_chain = LLMChain(llm = map_llm, prompt = eval_prompt)\n",
    "\n",
    "input_data = [\n",
    "    {\n",
    "        'question': \"What does it mean for a podcast summary to be catchy?\"\n",
    "    }  \n",
    "]\n",
    "\n",
    "# Run the input through the LLM chain (works in parallel)\n",
    "map_llm_chain_results = map_llm_chain.apply(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ' A catchy podcast summary is one that effectively captures the main points of the episode and entices listeners to tune in, often using engaging language and intriguing details. It should be concise and provide enough information for potential listeners to understand what they will gain from listening to the episode.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_llm_chain_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both openchat and openai have similar explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear\n",
    "(Clear,Concise,Consistent) https://www.linkedin.com/pulse/clear-concise-consistent-three-fundamentals-good-writing-gisler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = PromptTemplate(template=eval_prompt_template, input_variables=[])\n",
    "\n",
    "# Define the LLMs\n",
    "map_llm = ChatOllama(model=\"openchat\")\n",
    "\n",
    "map_llm_chain = LLMChain(llm = map_llm, prompt = eval_prompt)\n",
    "\n",
    "input_data = [\n",
    "    {\n",
    "        'question': \"What does it mean for a podcast summary to be clear?\"\n",
    "    }  \n",
    "]\n",
    "\n",
    "# Run the input through the LLM chain (works in parallel)\n",
    "map_llm_chain_results = map_llm_chain.apply(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \" A clear podcast summary provides a concise and accurate description of the episode's content, context, and key takeaways in an easily understandable manner.\"}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_llm_chain_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This one seems better than OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = PromptTemplate(template=eval_prompt_template, input_variables=[])\n",
    "\n",
    "# Define the LLMs\n",
    "map_llm = ChatOllama(model=\"openchat\")\n",
    "\n",
    "map_llm_chain = LLMChain(llm = map_llm, prompt = eval_prompt)\n",
    "\n",
    "input_data = [\n",
    "    {\n",
    "        'question': \"What does it mean for a podcast summary to be consistent?\"\n",
    "    }  \n",
    "]\n",
    "\n",
    "# Run the input through the LLM chain (works in parallel)\n",
    "map_llm_chain_results = map_llm_chain.apply(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ' A consistent podcast summary is one that maintains a similar tone, style, and focus across multiple episodes. It provides an accurate representation of the content and keeps listeners informed about the main topics discussed in each episode.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_llm_chain_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAI seems to be better.. Here it talks about 'across multiple episodes' which might not be correct.. \n",
    "the second sentence also doesn't seem to relate to consistency. \n",
    "It mentions tone and style but didn't mention 'structure' like Openai does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d228f8d1b134e326a52396b2016d42a4e7c84199cf5eb27412c1836171e03131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
