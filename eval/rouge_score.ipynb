{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install evaluate\n",
    "import evaluate\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6.27k/6.27k [00:00<00:00, 9.38MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### episode 22/23/79/94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama Openchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.46487603305785125, 'rouge2': 0.1656314699792961, 'rougeL': 0.22933884297520662, 'rougeLsum': 0.39256198347107435}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_content = None\n",
    "baseline_content = None\n",
    "\n",
    "with open(f\"./predicted/podcast_summaries_ollama_openchat_22_v3.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    predicted_content = json_data['final_summary']\n",
    "\n",
    "    \n",
    "with open(f\"./baseline/podcast_summaries_openai_gpt35turbo_22_v2.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    baseline_content = json_data['final_summary']\n",
    "    \n",
    "\n",
    "predictions = [predicted_content]\n",
    "references = [[baseline_content]]\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.25770308123249297, 'rouge2': 0.07887323943661972, 'rougeL': 0.1512605042016807, 'rougeLsum': 0.16806722689075632}\n"
     ]
    }
   ],
   "source": [
    "predicted_content = None\n",
    "baseline_content = None\n",
    "\n",
    "with open(f\"./predicted/podcast_summaries_ollama_openchat_23_v3.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    predicted_content = json_data['final_summary']\n",
    "\n",
    "    \n",
    "with open(f\"./baseline/podcast_summaries_openai_gpt35turbo_23_v2.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    baseline_content = json_data['final_summary']\n",
    "    \n",
    "\n",
    "predictions = [predicted_content]\n",
    "references = [[baseline_content]]\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.3552311435523114, 'rouge2': 0.1271393643031785, 'rougeL': 0.21897810218978103, 'rougeLsum': 0.26277372262773724}\n"
     ]
    }
   ],
   "source": [
    "predicted_content = None\n",
    "baseline_content = None\n",
    "\n",
    "with open(f\"./predicted/podcast_summaries_ollama_openchat_79_v3.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    predicted_content = json_data['final_summary']\n",
    "\n",
    "    \n",
    "with open(f\"./baseline/podcast_summaries_openai_gpt35turbo_79_v2.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    baseline_content = json_data['final_summary']\n",
    "    \n",
    "\n",
    "predictions = [predicted_content]\n",
    "references = [[baseline_content]]\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.4744027303754266, 'rouge2': 0.18150684931506847, 'rougeL': 0.25597269624573377, 'rougeLsum': 0.3310580204778157}\n"
     ]
    }
   ],
   "source": [
    "predicted_content = None\n",
    "baseline_content = None\n",
    "\n",
    "with open(f\"./predicted/podcast_summaries_ollama_openchat_94_v3.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    predicted_content = json_data['final_summary']\n",
    "\n",
    "    \n",
    "with open(f\"./baseline/podcast_summaries_openai_gpt35turbo_94_v2.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    baseline_content = json_data['final_summary']\n",
    "    \n",
    "\n",
    "predictions = [predicted_content]\n",
    "references = [[baseline_content]]\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.28716645489199494, 'rouge2': 0.14522292993630573, 'rougeL': 0.17789072426937738, 'rougeLsum': 0.22617534942820838}\n"
     ]
    }
   ],
   "source": [
    "predicted_content = None\n",
    "baseline_content = None\n",
    "\n",
    "with open(f\"./predicted/podcast_summaries_ollama_gemma_22.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    predicted_content = json_data['final_summary']\n",
    "\n",
    "    \n",
    "with open(f\"./baseline/podcast_summaries_openai_gpt35turbo_22_v2.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    baseline_content = json_data['final_summary']\n",
    "    \n",
    "\n",
    "predictions = [predicted_content]\n",
    "references = [[baseline_content]]\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.32189973614775724, 'rouge2': 0.14854111405835543, 'rougeL': 0.2005277044854881, 'rougeLsum': 0.24274406332453827}\n"
     ]
    }
   ],
   "source": [
    "predicted_content = None\n",
    "baseline_content = None\n",
    "\n",
    "with open(f\"./predicted/podcast_summaries_ollama_gemma_23.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    predicted_content = json_data['final_summary']\n",
    "\n",
    "    \n",
    "with open(f\"./baseline/podcast_summaries_openai_gpt35turbo_23_v2.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    baseline_content = json_data['final_summary']\n",
    "    \n",
    "\n",
    "predictions = [predicted_content]\n",
    "references = [[baseline_content]]\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.2356164383561644, 'rouge2': 0.0881542699724518, 'rougeL': 0.17534246575342466, 'rougeLsum': 0.1972602739726027}\n"
     ]
    }
   ],
   "source": [
    "predicted_content = None\n",
    "baseline_content = None\n",
    "\n",
    "with open(f\"./predicted/podcast_summaries_ollama_gemma_79.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    predicted_content = json_data['final_summary']\n",
    "\n",
    "    \n",
    "with open(f\"./baseline/podcast_summaries_openai_gpt35turbo_79_v2.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    baseline_content = json_data['final_summary']\n",
    "    \n",
    "\n",
    "predictions = [predicted_content]\n",
    "references = [[baseline_content]]\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.4082474226804124, 'rouge2': 0.19875776397515527, 'rougeL': 0.24329896907216494, 'rougeLsum': 0.3505154639175258}\n"
     ]
    }
   ],
   "source": [
    "predicted_content = None\n",
    "baseline_content = None\n",
    "\n",
    "with open(f\"./predicted/podcast_summaries_ollama_gemma_94.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    predicted_content = json_data['final_summary']\n",
    "\n",
    "    \n",
    "with open(f\"./baseline/podcast_summaries_openai_gpt35turbo_94_v2.json\") as f: \n",
    "    json_data = json.load(f)\n",
    "    baseline_content = json_data['final_summary']\n",
    "    \n",
    "\n",
    "predictions = [predicted_content]\n",
    "references = [[baseline_content]]\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claude 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d228f8d1b134e326a52396b2016d42a4e7c84199cf5eb27412c1836171e03131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
