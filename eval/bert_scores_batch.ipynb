{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "V-tUvCW7zwHu",
    "outputId": "d8b92234-7001-44ba-9563-de57feb678fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bizon/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1168cb0330>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "# df = pd.read_csv('tech_file.csv')\n",
    "# orig_txt = df['transcript'][25]\n",
    "import torch\n",
    "import random\n",
    "from evaluate import load\n",
    "\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bertscore = load(\"bertscore\")\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.9999999403953552, 1.0],\n",
       " 'recall': [0.9999999403953552, 1.0],\n",
       " 'f1': [0.9999999403953552, 1.0],\n",
       " 'hashcode': 'roberta-large_L17_no-idf_version=0.3.9(hug_trans=4.31.0)'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "podcast_data = []\n",
    "row_num = 0\n",
    "with open('../summarize/vtt_data.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='|')\n",
    "    for row in reader:\n",
    "        row_num += 1\n",
    "        \n",
    "        if row_num == 1:\n",
    "            continue\n",
    "            \n",
    "        filename = row[5]\n",
    "        if not filename.endswith(\"_large.vtt\"):\n",
    "            continue\n",
    "\n",
    "        podcast = {    \n",
    "            \"episode_index\": row[0],    \n",
    "            \"guest\": row[1],\n",
    "            \"episode_name\": row[2],\n",
    "            \"host_name\": row[3],\n",
    "            \"episode_number\": row[4],\n",
    "            \"transcript\": row[6],\n",
    "            \"duration\": row[7],\n",
    "        }\n",
    "        podcast_data.append(podcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark_summaries = {\n",
    "#     \"12\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_12_benchmark.json\",\n",
    "#     \"22\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_22_benchmark.json\",\n",
    "#     \"23\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_23_benchmark.json\",\n",
    "#     \"94\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_94_benchmark.json\",\n",
    "# }\n",
    "\n",
    "# keypoints_summaries = {\n",
    "#     \"12\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_12_stage3_extractkeypoints_v2b4.json\",\n",
    "#     \"22\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_22_stage3_extractkeypoints_v2b4.json\",\n",
    "#     \"23\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_23_stage3_extractkeypoints_v2b4.json\",\n",
    "#     \"94\" : \"../summarize/summarized_dataset/podcast_summaries_openai_gpt35turbo_94_stage3_extractkeypoints_v2b4_ep94only.json\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1HHVBn6kIRk",
    "outputId": "ea38fca8-d136-4e51-efa9-a96c407381d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating score for episode: 3\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_3_benchmark.json\n",
      "Calculating score for episode: 4\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_4_benchmark.json\n",
      "Calculating score for episode: 5\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_5_benchmark.json\n",
      "Calculating score for episode: 6\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_6_benchmark.json\n",
      "Calculating score for episode: 7\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_7_benchmark.json\n",
      "Calculating score for episode: 9\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_9_benchmark.json\n",
      "Calculating score for episode: 10\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_10_benchmark.json\n",
      "Calculating score for episode: 11\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_11_benchmark.json\n",
      "Calculating score for episode: 13\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_13_benchmark.json\n",
      "Calculating score for episode: 14\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_14_benchmark.json\n",
      "Calculating score for episode: 15\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_15_benchmark.json\n",
      "Calculating score for episode: 17\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_17_benchmark.json\n",
      "Calculating score for episode: 18\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_18_benchmark.json\n",
      "Calculating score for episode: 19\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_19_benchmark.json\n",
      "Calculating score for episode: 20\n",
      "summary file path: ../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_20_benchmark.json\n",
      "benchmark_results:\n",
      "{'precision': [0.8184678554534912, 0.8213446140289307, 0.8262778520584106, 0.8299638032913208, 0.8316537737846375, 0.8130732774734497, 0.8231320977210999, 0.8402954339981079, 0.8265548944473267, 0.8257153630256653, 0.8243153691291809, 0.8205175399780273, 0.8434783220291138, 0.8386285901069641, 0.8304635286331177], 'recall': [0.8124667406082153, 0.8134102821350098, 0.8095169067382812, 0.8213744759559631, 0.81656414270401, 0.8001154661178589, 0.8122246265411377, 0.8322938084602356, 0.8057324886322021, 0.8104310035705566, 0.8125729560852051, 0.8152313232421875, 0.837624192237854, 0.8227144479751587, 0.817176103591919], 'f1': [0.8154562711715698, 0.8173581957817078, 0.8178114891052246, 0.8256467580795288, 0.824039876461029, 0.8065423369407654, 0.8176419734954834, 0.8362754583358765, 0.8160108923912048, 0.8180018067359924, 0.8184020519256592, 0.8178658485412598, 0.8405411243438721, 0.8305952548980713, 0.8237662315368652], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.9(hug_trans=4.31.0)'}\n",
      "keypoint_results:\n",
      "{'precision': [0.8387696743011475, 0.8296501636505127, 0.8331043720245361, 0.8217743635177612, 0.8339159488677979, 0.8176705837249756, 0.8369873762130737, 0.842628002166748, 0.8261592388153076, 0.8382620811462402, 0.8340899348258972, 0.8335209488868713, 0.8611700534820557, 0.8391602635383606, 0.8364254236221313], 'recall': [0.8313002586364746, 0.8202710747718811, 0.8261962532997131, 0.8112622499465942, 0.8201026320457458, 0.8075376749038696, 0.8247935175895691, 0.8336519002914429, 0.8105741143226624, 0.8184158802032471, 0.8264917731285095, 0.8210680484771729, 0.856585681438446, 0.8253077268600464, 0.826697587966919], 'f1': [0.8350182771682739, 0.8249340057373047, 0.8296359777450562, 0.8164844512939453, 0.8269515633583069, 0.8125725388526917, 0.8308457732200623, 0.838115930557251, 0.818292498588562, 0.8282201290130615, 0.8302735090255737, 0.827247679233551, 0.8588717579841614, 0.8321763277053833, 0.8315330147743225], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.9(hug_trans=4.31.0)'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transcripts = []\n",
    "benchmarks = []\n",
    "keypoints = []\n",
    "\n",
    "# 15 more\n",
    "episodes_number = [\n",
    "    3,4,5,6,7,9,10,11,13,14,15,17,18,19,20\n",
    "]\n",
    "\n",
    "count = 0\n",
    "for podcast in podcast_data:\n",
    "\n",
    "    episode_number = podcast['episode_number']\n",
    "    \n",
    "    if int(episode_number) not in episodes_number:\n",
    "        continue\n",
    "    \n",
    "    transcripts.append(podcast['transcript'])\n",
    "    \n",
    "    print(f\"Calculating score for episode: {episode_number}\")    \n",
    "    summary = f\"../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_{episode_number}_benchmark.json\"\n",
    "\n",
    "    print(\"summary file path: \" + str(summary))\n",
    "    summary_json = None\n",
    "    with open(summary) as f:\n",
    "        summary_json = json.load(f)\n",
    "    \n",
    "    benchmarks.append(summary_json['final_summary'])\n",
    "    \n",
    "    # keypoints\n",
    "    summary = f\"../summarize/summarized_dataset_batch/podcast_summaries_openai_gpt35turbo_{episode_number}_stage3_extractkeypoints_v2b4.json\"\n",
    "    \n",
    "    summary_json = None\n",
    "    with open(summary) as f:\n",
    "        summary_json = json.load(f)\n",
    "    \n",
    "    keypoints.append(summary_json['final_summary'])\n",
    "\n",
    "    \n",
    "benchmark_results = bertscore.compute(predictions=benchmarks, references=transcripts, lang=\"en\")\n",
    "    \n",
    "print(\"benchmark_results:\")\n",
    "print(benchmark_results)\n",
    "\n",
    "keypoint_results = bertscore.compute(predictions=keypoints, references=transcripts, lang=\"en\")\n",
    "\n",
    "print(\"keypoint_results:\")\n",
    "print(keypoint_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NE benchmark_results_avg_precision: 0.8276\n",
      "NE benchmark_results_avg_recall: 0.8160\n",
      "NE keypoint_results_avg_precision: 0.8349\n",
      "NE keypoint_results_avg_recall: 0.8240\n"
     ]
    }
   ],
   "source": [
    "\n",
    "benchmark_results_avg_precision = sum(benchmark_results['precision'])/len(benchmark_results['precision'])\n",
    "benchmark_results_avg_recall = sum(benchmark_results['recall'])/len(benchmark_results['recall'])\n",
    "\n",
    "print(f\"NE benchmark_results_avg_precision: {benchmark_results_avg_precision:.4f}\")\n",
    "print(f\"NE benchmark_results_avg_recall: {benchmark_results_avg_recall:.4f}\")\n",
    "\n",
    "keypoint_results_avg_precision = sum(keypoint_results['precision'])/len(keypoint_results['precision'])\n",
    "keypoint_results_avg_recall = sum(keypoint_results['recall'])/len(keypoint_results['recall'])\n",
    "\n",
    "print(f\"NE keypoint_results_avg_precision: {keypoint_results_avg_precision:.4f}\")\n",
    "print(f\"NE keypoint_results_avg_recall: {keypoint_results_avg_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
