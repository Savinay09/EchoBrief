{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from langchain import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "episodes = [22,23,79,94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt_template = \"\"\"You are comparing predicted_summary and baseline_summary and \n",
    "trying to determine if the predicted_summary is accurate using the baseline_summary as the source of truth.\n",
    "\n",
    "\n",
    "Here is the data:\n",
    "[BEGIN DATA]\n",
    "************\n",
    "[predicted_summary]: {predicted_summary}\n",
    "************\n",
    "[baseline_summary]: {baseline_summary}\n",
    "[END DATA]\n",
    "\n",
    "\n",
    "Your response must be either Very, Most, Somewhat, or Not. Your response should not contain any text\n",
    "or characters aside from that.\n",
    "\n",
    "The string Very means that predicted_summary is a very accurate.\n",
    "\n",
    "The string Mostly means that predicted_summary is a mostly accurate.\n",
    "\n",
    "The string Somewhat means that predicted_summary is a somewhat accurate.\n",
    "\n",
    "The string Not means that predicted_summary is not accurate.\n",
    "\n",
    "You response should also contain reasons behind your evaluation.\n",
    "\n",
    "Return your answer in the following format:\n",
    "  Very/Mostly/Somewhat/Not | reasons...\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######  Episode 22\n",
      "## Predicted Summary\n",
      "The podcast describes the growth of deep learning and machine learning, highlighting the success of AI projects and the open-source nature of TensorFlow. It also discusses the impact of open-source projects on technology and the overall impact of TensorFlow on the AI community.\n",
      "\n",
      "The podcast summarizes the key points of various articles about paid services, advertising on the internet, AI, and its potential impact on education and advertising. It highlights the accessibility and power of AI tools like TPUs, cloud services, and TensorFlow, as well as the benefits of platforms like Colab for machine learning beginners. Additionally, it explores the impact of advertising on information accessibility and its potential for connecting users to desired products.\n",
      "\n",
      "The podcast concludes by discussing the future of advertising and monetization on the internet. It emphasizes the potential of AI to revolutionize the advertising industry and its ability to connect users with relevant content.\n",
      "## End of Predicted Summary\n",
      "\n",
      "## Baseline Summary\n",
      "In this podcast, Rajat Manga, director of Google's TensorFlow team, discusses the evolution of TensorFlow from a software library to an ecosystem of tools for deploying machine learning. The decision to open source TensorFlow is seen as a defining moment in the tech industry, inspiring open innovation and the exchange of ideas. The podcast explores the early days of Google Brain and the potential of deep learning, as well as the impact of scaling data and computing power on the performance of machine learning models. It also discusses the development of TensorFlow, including the considerations for use cases and hardware support.\n",
      "\n",
      "The podcast also explores the customization of handcrafted code and internal libraries for machine learning, focusing on Theano, Caffe, and TensorFlow 2.0 at Google. It discusses the decision-making process behind choosing a machine learning library, the evolution of using graphs in machine learning, and the unexpected popularity and growth of deep learning. The podcast also highlights the role of deep learning in enterprise, the stability and usability of older models, and the challenges of implementing machine learning in various industries.\n",
      "\n",
      "Additionally, the podcast discusses the decision to simplify and integrate Keras into TensorFlow, making it easier for users to navigate and choose the right API for their needs. It explores the decision-making process in open source projects, the evolution of Keras and its relationship with TensorFlow, and the developer's role in the community. The integration of Keras into TensorFlow has simplified the use of TensorFlow for beginners and enterprises, making transfer learning and basic use cases much simpler.\n",
      "\n",
      "The podcast also delves into the competition between TensorFlow and PyTorch, emphasizing the importance of learning from the competition to improve their own platform. It discusses the integration of eager execution in TensorFlow 2.0 and its impact on development, as well as the potential for increased performance and efficiency. The restructuring of TensorFlow into more modular pieces is also highlighted, with an emphasis on making the ecosystem more accessible for collaboration and development.\n",
      "\n",
      "Furthermore, the podcast explores the potential evolution of hardware accelerators and TensorFlow, including the possibility of training with four bits instead of 32 bits and the coevolution of TPU and TensorFlow. The conversation also touches on making TensorFlow more accessible for beginners and the challenges they may face. It also explores the challenges and solutions for beginners using TensorFlow, the potential for major corporations to utilize TensorFlow, and the factors that contribute to the growth and success of open source communities, using TensorFlow as a case study. The speaker also discusses the future of machine learning and AI technologies, predicting the continued prominence of certain technologies and potential advancements in the next five years.\n",
      "\n",
      "The podcast also emphasizes the impact of cohesive teams and motivated individuals in cutting-edge technology projects, using Google's hiring process and the development of TensorFlow as examples. It emphasizes the importance of team cohesion, motivation, and culture fit in product development, as well as the balance between speed and quality in meeting deadlines. The conversation also delves into the value of quick iteration and experimentation in software development, highlighting the ongoing development and upcoming release of TensorFlow 2.0.\n",
      "\n",
      "Finally, the podcast explores the potential of search ads to connect users with what they need, the role of machine learning in improving user experience, and the challenges and opportunities in the world of search ads. It discusses the importance of aligning ads with user needs and maintaining a minimum quality level, as well as the future of paid content on the internet. The conversation also delves into the use of technology like TPUs and TensorFlow in education, and the benefits and limitations of using cloud computing for machine learning. The podcast provides valuable insights for beginners interested in machine learning and TensorFlow.\n",
      "## End of Baseline Summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bizon/anaconda3/envs/w210_podcast_ollama/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Truthfulness evaluation score for episode 22\n",
      "[{'text': 'Somewhat | The predicted_summary covers some key points from the baseline_summary, such as the growth of deep learning and machine learning, the open-source nature of TensorFlow, and the impact of AI on advertising and education. However, it misses important details about the evolution of TensorFlow, the competition with PyTorch, the integration of Keras, and the potential evolution of hardware accelerators. Overall, it captures the general theme but lacks specific details from the baseline_summary.'}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n",
      "#######  Episode 23\n",
      "## Predicted Summary\n",
      "The podcast explores various topics related to creativity, technology, and personal growth, highlighting the interconnectedness of various fields and the potential impact of AI on various aspects of human experience. It covers topics such as AI and creativity, poetry and AI, home automation, the intersection of technology and literature, and the potential for AI to enhance learning and improve quality control. The podcast emphasizes the potential benefits of AI in streamlining processes, unlocking new possibilities, and fostering human-machine collaboration.\n",
      "\n",
      "Overall, the podcast explores the potential of AI to revolutionize various fields and aspects of human experience, emphasizing its ability to enhance creativity, streamline workflows, and facilitate learning and problem-solving.\n",
      "## End of Predicted Summary\n",
      "\n",
      "## Baseline Summary\n",
      "Dr. Gavin Miller, head of Adobe Research, discusses the future of Adobe's creative software and the innovative applications of AI in creating images, video, audio, and language. The conversation delves into the balance between technology and creativity, offering insights into the intersection of these two fields. Dr. Miller also shares a humorous poem about dieting and weight loss, reflecting on the deeper meaning behind his poetry and how it fits into his life and career. The podcast explores the ways in which creativity and technology intersect, with a focus on how writing, art, and poetry can contribute to research and work in the tech industry.\n",
      "\n",
      "The podcast explores the importance of AI in understanding and describing concepts from different perspectives, using examples like automatic image captioning and the evolution of 3D computer graphics. It discusses the impact of AI on streamlining creative processes, particularly in image editing and manipulation, and highlights the potential for neural nets to revolutionize image recognition and background removal. The speaker emphasizes the value of robust neural nets that can provide high-quality results with minimal user input, ultimately making workflows more efficient.\n",
      "\n",
      "The podcast also delves into the potential impact of adaptive characters in augmented reality on the broader commercial sphere and the potential benefits of using augmented reality and immersive technology in 3D design. It discusses the importance of internships in research labs, highlighting their role in fostering talent, innovation, and enduring relationships with university departments. The podcast ends with a favorite poem that contemplates mortality and immortality, leaving the listener with a sense of wonder and curiosity about the future.\n",
      "## End of Baseline Summary\n",
      "\n",
      "Truthfulness evaluation score for episode 23\n",
      "[{'text': \"Not | The predicted_summary and baseline_summary cover completely different topics and themes. The predicted_summary focuses on the potential impact of AI on creativity, technology, and personal growth, while the baseline_summary discusses Adobe's creative software, the intersection of technology and creativity, and the applications of AI in creating images, video, audio, and language. The predicted_summary does not accurately reflect the content of the baseline_summary.\"}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n",
      "#######  Episode 79\n",
      "## Predicted Summary\n",
      "The podcast explores various topics related to science, philosophy, and technology. It covers concepts such as first principles, the constructed nature of reality, scientific methodology, ethics, quantum theory, and non-locality. The podcast emphasizes the importance of rigorous scientific methods, ethical principles, and open-mindedness. It also highlights the limitations of human understanding and the need for humility and openness to new perspectives. Overall, the podcast provides a wide-ranging exploration of key ideas and concepts, encompassing diverse fields of study and inviting further exploration.\n",
      "## End of Predicted Summary\n",
      "\n",
      "## Baseline Summary\n",
      "The podcast features theoretical physicist Lee Smolin discussing his contributions to cosmology, quantum field theory, and his critiques of string theory. It explores the intersection of theoretical physics and AI, delving into the fundamental nature of the universe and the human mind. The conversation challenges listeners to consider the nature of reality and the limits of human understanding, exploring the concept that our human perception constructs our reality. It also discusses the origins of human curiosity, our need to explain the world around us, and the necessity of making fast judgments in order to survive.\n",
      "\n",
      "The podcast explores the concept of realism in physics, discussing the belief in an external world independent of our existence and the possibility of an objective description of fundamental processes. It delves into the deterministic nature of the fundamental laws of physics and the potential for their change, challenging the idea of a fixed and predictable universe. The conversation also explores the impact of self-confidence on the progress of theoretical physics, focusing on the unfinished revolution of Einstein's theories. It discusses the need for additional degrees of freedom, particles, and forces to provide a complete description of each phenomenon, as well as the debate and friendly rivalry between proponents of different quantum mechanics theories, particularly focusing on the many worlds interpretation.\n",
      "\n",
      "The podcast also delves into the challenges of finding a correct approach to quantum gravity, referencing the work of David Wallace and Sean Carroll, and features physicist Andy Straminger discussing the complexities and potential breakthroughs in the field of quantum gravity and string theory. The conversation emphasizes the importance of diverse ideas coming together in the pursuit of scientific and technological innovation.\n",
      "## End of Baseline Summary\n",
      "\n",
      "Truthfulness evaluation score for episode 79\n",
      "[{'text': \"Not | The predicted_summary does not accurately reflect the content of the baseline_summary. The predicted_summary focuses on a wide range of topics related to science, philosophy, and technology, while the baseline_summary specifically discusses theoretical physicist Lee Smolin's contributions to cosmology, quantum field theory, and critiques of string theory. The predicted_summary does not capture the specific details and discussions presented in the baseline_summary.\"}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n",
      "#######  Episode 94\n",
      "## Predicted Summary\n",
      "The text explores various topics related to neural networks, deep learning, and artificial intelligence. It covers neural networks, generative adversarial networks (GANs), language representation, object recognition, overparameterization, and training large neural networks. The text also discusses the similarities between human and artificial neural networks, as well as the potential of spiking neural networks.\n",
      "\n",
      "The text highlights the advancements in neural network technology and its impact on various fields. It explores the potential of deep learning in unifying physics and neuroscience, as well as its potential benefits and challenges in various other fields. The text also discusses the ethical implications of AI and its potential impact on society.\n",
      "\n",
      "Overall, the text provides a concise overview of key concepts and advancements in the field of neural networks and deep learning. It emphasizes the power of deep learning and its potential to revolutionize various fields.\n",
      "## End of Predicted Summary\n",
      "\n",
      "## Baseline Summary\n",
      "In this podcast, Ilya Sotskever, cofounder and chief scientist of OpenAI, discusses the future of artificial intelligence and its impact on society, with a focus on the intersection of AI and finance, including cryptocurrency and the history of money. The conversation explores the evolution of neural networks, their potential for advancing robotics and STEM education, and the concept of overparameterization in neural networks. The discussion also touches on doubts surrounding the ability to train large neural networks and the breakthroughs that have led to faster training methods.\n",
      "\n",
      "The podcast delves into the connection between the human brain and artificial neural networks, discussing the evolution of deep learning and the analogies between the two. It explores the advantages and disadvantages of artificial neural networks compared to the human brain, as well as the potential resurgence of recurrent neural networks in the field of artificial intelligence. The conversation also explores the concept of maintaining a hidden state as a knowledge base within neural networks and the potential for building large scale knowledge bases within these networks.\n",
      "\n",
      "The podcast also discusses the potential for unification between reinforcement learning and supervised learning, the challenges and similarities between vision and language processing in machine learning, and the potential for a unified system that can handle a wide range of inputs and tasks. It explores the lasting impact of human relationships and the surprising capabilities of artificial intelligence, as well as the challenges and surprising properties of deep learning, including the necessity of compute power, the phenomenon of double descent, the concept of overfitting, and the impact of dimensionality on model performance.\n",
      "\n",
      "The podcast also delves into the theoretical limits of data prediction, the potential for deep neural networks to revolutionize the process of finding programs, and the impact of machine learning and deep learning on solving mathematical problems. It discusses the implications of releasing AI models like GPT2 in stages, the components necessary for creating artificial general intelligence (AGI), and the pursuit of happiness, the potential of machine learning, and the alignment of AI values with human values.\n",
      "## End of Baseline Summary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Truthfulness evaluation score for episode 94\n",
      "[{'text': 'Somewhat | The predicted_summary covers some similar topics as the baseline_summary, such as neural networks, deep learning, and artificial intelligence. However, the predicted_summary focuses more on the advancements and potential of these technologies, while the baseline_summary delves into a wider range of specific topics and discussions. The predicted_summary also lacks some of the in-depth discussions and details provided in the baseline_summary, making it somewhat accurate but not fully capturing the breadth of information in the baseline_summary.'}]\n",
      "##############################################\n",
      "##############################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for episode in episodes:\n",
    "\n",
    "    with open(f\"./predicted/podcast_summaries_ollama_gemma_{episode}.json\") as f: \n",
    "        json_data = json.load(f)\n",
    "        summarized_content = json_data['final_summary']\n",
    "\n",
    "    with open(f\"./baseline/podcast_summaries_openai_gpt35turbo_{episode}_v2.json\") as f: \n",
    "        json_data = json.load(f)\n",
    "        baseline_summary = json_data['final_summary']\n",
    "\n",
    "    eval_input_data = [\n",
    "        {\n",
    "            'predicted_summary': summarized_content,   \n",
    "            'baseline_summary': baseline_summary,     \n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"#######  Episode {episode}\")\n",
    "    print(\"## Predicted Summary\")\n",
    "    print(summarized_content)\n",
    "    print(\"## End of Predicted Summary\")\n",
    "    \n",
    "    print()\n",
    "    print(\"## Baseline Summary\")\n",
    "    print(baseline_summary)\n",
    "    print(\"## End of Baseline Summary\")\n",
    "    \n",
    "    eval_prompt = PromptTemplate(template=eval_prompt_template, input_variables=[\"predicted_summary\", \"baseline_summary\"])\n",
    "\n",
    "    # Define the LLMs\n",
    "    map_llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo-1106')\n",
    "\n",
    "    map_llm_chain = LLMChain(llm = map_llm, prompt = eval_prompt)\n",
    "\n",
    "    map_llm_chain_input = eval_input_data\n",
    "    # Run the input through the LLM chain (works in parallel)\n",
    "    map_llm_chain_results = map_llm_chain.apply(map_llm_chain_input)\n",
    "    print()\n",
    "\n",
    "    print(f\"Truthfulness evaluation score for episode {episode}\")\n",
    "    print(map_llm_chain_results)\n",
    "    print(\"##############################################\")\n",
    "    print(\"##############################################\")\n",
    "    print()\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d228f8d1b134e326a52396b2016d42a4e7c84199cf5eb27412c1836171e03131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
